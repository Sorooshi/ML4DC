{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time \n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import data_normalization\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter, attrgetter \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Sorting in the form of Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### FEATURES:\n",
    "Some the features are as follows:\n",
    "\n",
    "[$P_T$\", \"$\\eta$\", \"$\\phi$\" , \"$\\eta$\", \"$\\phi$\", \"$f_{x}$\", \"$f_{y}$\", \"$f_{z}$\", \"m\"] \n",
    "\n",
    "Where\n",
    "\n",
    "• \"$P_T$\" — traverse momentum;\n",
    "\n",
    "• \"$\\eta$\", \"$\\phi$\" — pseudo-rapidity and angle between the transverse direction and the horizontal plane;\n",
    "\n",
    "• \"$f_{x}$\", \"$f_{y}$\", \"$f_{z}$\" — coordinates of the reconstructed origin;\n",
    "\n",
    "• \"m\" — reconstructed object mass for composed objects.\n",
    "\n",
    "• More information about each particle's feature can be found in the following cell. \n",
    "(Features are determined by Franceso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# VERY IMPORTANT NOTE:\n",
    "\n",
    "## VERY IMPORTANT NOTE\n",
    "\n",
    "\n",
    "### VERY IMPORTANT NOTE\n",
    "\n",
    "\n",
    "#### VERY IMPORTANT NOTE\n",
    "\n",
    " Initially, I assumed the \"isSig\" value describes the label of the corresponding Lumisection. Consequently, I used it as a label constructor during the data preparation.\n",
    "However, it seems (I AM NOT SURE) there are some inconsistencies in this parameter. \n",
    "Therefore, I highly recommend using the two following commands in order to prepare the labels of good and bad data:\n",
    "\n",
    "labels_good = numpy.repeat(1, Y_good.shape[0])  \n",
    "labels_bad  = numpy.repeat(1, Y_bad.shape[0])  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Features, taken from Francesco's gitub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZEROBIAS_FEATURES = [\"qpVtxChi2_\", \"qpVtxNtr_\", \"qpVtxX_\", \"qpVtxY_\", \"qpVtxZ_\", \"qPUEvt\", \"qlumiEvt\",\n",
    "                     \n",
    "                     \"qgTkPt\", \"qgTkEta\", \"qgTkPhi\", \"qgTkN\", \"qgTkChi2\", \"qgTkNHits\",\n",
    "                    ]\n",
    "\n",
    "JETHT_FEATURES = [\"qpVtxChi2_\", \"qpVtxNtr_\", \"qpVtxX_\", \"qpVtxY_\", \"qpVtxZ_\", \"qPUEvt\", \"qlumiEvt\",\n",
    "                  \n",
    "                  \"qPFJetPt\", \"qPFJetPhi\", \"qPFJetEta\", \"qPFMetPt\", \"qPFMetPhi\",\n",
    "                  \n",
    "                  \"qCalJetPt\", \"qCalJetEta\", \"qCalJetPhi\", \"qCalJetEn\", \"qCalMETPt\", \"qCalMETPhi\",\n",
    "                  \n",
    "                  \"qCCEn\", \"qCCEta\", \"qCCPhi\",\n",
    "                  \"qSCEn\", \"qSCEta\", \"qSCPhi\",\n",
    "                 ]\n",
    "\n",
    "EGAMMA_FEATURES = [ \"qpVtxChi2_\", \"qpVtxNtr_\", \"qpVtxX_\", \"qpVtxY_\", \"qpVtxZ_\", \"qPUEvt\", \"qlumiEvt\",\n",
    "                   \n",
    "                   \"qgTkPt\", \"qgTkEta\", \"qgTkPhi\",\n",
    "\n",
    "                   \"qPhoPt\", \"qPhoEta\",  \"qPhoPhi\", \"qPhoEn_\", \"qPhoe1x5_\", \"qPhoe3x3_\", \n",
    "                   \n",
    "                   \"qgedPhoPt\", \"qgedPhoEta\", \"qgedPhoPhi\", \"qgedPhoEn_\", \"qgedPhoe1x5_\", \"qgedPhoe3x3_\",\n",
    "                   \n",
    "                   \"qSigmaIEta\", \"qSigmaIPhi\", \"qr9\", \"qHadOEm\",\n",
    "                   \n",
    "                    \"qdrSumPt\", \"qdrSumEt\", \"qeSCOP\", \"qecEn\"\n",
    "                  ]\n",
    "\n",
    "SINGLEMUON_FEATURES = [ \"qpVtxChi2_\", \"qpVtxNtr_\", \"qpVtxX_\", \"qpVtxY_\", \"qpVtxZ_\", \"qPUEvt\", \"qlumiEvt\",\n",
    "                       \n",
    "                       \"qglobTkPt\", \"qglobTkEta\", \"qglobTkPhi\", \"qglobTkN\", \"qglobTkChi2\", \"qglobTkNHits\",\n",
    "                       \n",
    "                       \"qMuPt\", \"qMuEta\", \"qMuPhi\", \"qMuEn_\", \"qMuChi2_\",\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_array_all_events(files, paths, features, data_type):\n",
    "    \n",
    "    F = len(files) # Number of AODTree files in a directory(ies)\n",
    "    E = 600  #files[0].size  # Number of lumisections in each file  (600 events in each file)\n",
    "    V = len(features)*7 +1+1+1+1 # number of features + lumi + lumiId + RunID + label\n",
    "    X = np.zeros([F*E, V],)  # numpy array with selected features  dtype=\"float32\"\n",
    "    y = np.zeros(F*E)  # good labels\n",
    "    inconsistencies = {}\n",
    "\n",
    "    row_interval = 0  \n",
    "    feature_interval = 0\n",
    "\n",
    "    for f in range(F):  # Files\n",
    "\n",
    "        inconsistencies[paths[f]] = {}\n",
    "\n",
    "        for e in range(files[f].size):  # Number of Lumisections in each file\n",
    "\n",
    "            bad_feature = False\n",
    "\n",
    "            inconsistencies[paths[f]][e] = {}\n",
    "            inconsistencies[paths[f]][e]['Features'] = []\n",
    "            inconsistencies[paths[f]][e]['Len_Features'] = []\n",
    "            inconsistencies[paths[f]][e]['Val_Features'] = []\n",
    "\n",
    "            # Because there are some in inconsistencies in data taking process, \n",
    "            # e.g. different dimention of features and so forth\n",
    "            for feature in range(len(features)): \n",
    "                if len(files[f][features[feature]][e].tolist()) != 7: \n",
    "                    bad_feature = True\n",
    "\n",
    "            if bad_feature is False:\n",
    "                for feature in range(len(features)):\n",
    "                    \n",
    "                    X[e+row_interval, feature_interval: feature_interval+7] = files[f][features[feature]][e]\n",
    "                    feature_interval += files[f][features[feature]][e].shape[0]  # equal to += 7\n",
    "\n",
    "                X[e+row_interval, feature_interval] = files[f]['lumi'][e]  # Luminosity [0] or [?]\n",
    "                feature_interval +=1 \n",
    "                X[e+row_interval, feature_interval] = files[f]['runId'][e]\n",
    "                feature_interval +=1\n",
    "                X[e+row_interval, feature_interval] = files[f]['lumiId'][e]  # Lumisection ID \n",
    "                feature_interval +=1\n",
    "                if data_type.lower() == 'good':\n",
    "                    X[e+row_interval, feature_interval] = 0\n",
    "                elif data_type.lower() == 'bad':\n",
    "                    X[e+row_interval, feature_interval] = 1\n",
    "                    \n",
    "                    \n",
    "\n",
    "                y[e+row_interval] = files[f]['isSig'][e]\n",
    "#                 print(\"feature_interval\", feature_interval)\n",
    "\n",
    "                feature_interval = 0 \n",
    "\n",
    "            else:\n",
    "                for feature in range(len(features)): \n",
    "                    if len(files[f][features[feature]][e].tolist()) != 7: \n",
    "                        inconsistencies[paths[f]][e]['RunID'] = files[f]['runId'][e]\n",
    "                        inconsistencies[paths[f]][e]['Lumi'] = files[f]['lumi'][e]\n",
    "                        inconsistencies[paths[f]][e]['LuminID'] = files[f]['lumiId'][e]\n",
    "                        inconsistencies[paths[f]][e]['Features'].append(features[feature])\n",
    "                        inconsistencies[paths[f]][e]['Len_Features'].append(\n",
    "                            len(files[f][features[feature]][e].tolist()))\n",
    "                        inconsistencies[paths[f]][e]['Val_Features'].append(\n",
    "                            files[f][features[feature]][e].tolist())\n",
    "    #             print(\"Inconsistencies!\")\n",
    "\n",
    "        row_interval += files[f].size\n",
    "                \n",
    "    return X, y, inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us consider an sample Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Events in a Lumisection: (600,)\n"
     ]
    }
   ],
   "source": [
    "a_sample_tree = np.load('cms_ml4dc(NEW)/good_data/JetHT/crab_20190624_142408/190624_122412/0000/AODTree_1.npy', allow_pickle=True, encoding='bytes')\n",
    "print(\"Number of Events in a Lumisection:\", a_sample_tree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('runId', '<i4'), ('lumiId', '<i4'), ('lumi', '<f4'), ('isSig', '<i4'), ('PU', '<f4'), ('qpVtxChi2_', 'O'), ('qpVtxNtr_', 'O'), ('qpVtxX_', 'O'), ('qpVtxY_', 'O'), ('qpVtxZ_', 'O'), ('qgTkPt', 'O'), ('qgTkEta', 'O'), ('qgTkPhi', 'O'), ('qgTkN', 'O'), ('qgTkChi2', 'O'), ('qgTkNHits', 'O'), ('qglobTkPt', 'O'), ('qglobTkEta', 'O'), ('qglobTkPhi', 'O'), ('qglobTkN', 'O'), ('qglobTkChi2', 'O'), ('qglobTkNHits', 'O'), ('qPUEvt', 'O'), ('qlumiEvt', 'O'), ('qPFJetPt', 'O'), ('qPFJetEta', 'O'), ('qPFJetPhi', 'O'), ('qPFJet4CHSPt', 'O'), ('qPFJet4CHSEta', 'O'), ('qPFJet4CHSPhi', 'O'), ('qPFJet8CHSPt', 'O'), ('qPFJet8CHSEta', 'O'), ('qPFJet8CHSPhi', 'O'), ('qPFJetEIPt', 'O'), ('qPFJetEIEta', 'O'), ('qPFJetEIPhi', 'O'), ('qPFJet8CHSSDPt', 'O'), ('qPFJet8CHSSDEta', 'O'), ('qPFJet8CHSSDPhi', 'O'), ('qPFJetTopCHSPt', 'O'), ('qPFJetTopCHSEta', 'O'), ('qPFJetTopCHSPhi', 'O'), ('qPFChMetPt', 'O'), ('qPFChMetPhi', 'O'), ('qPFMetPt', 'O'), ('qPFMetPhi', 'O'), ('qNVtx', 'O'), ('qCalJetPt', 'O'), ('qCalJetEta', 'O'), ('qCalJetPhi', 'O'), ('qCalJetEn', 'O'), ('qCalMETPt', 'O'), ('qCalMETPhi', 'O'), ('qCalMETEn', 'O'), ('qCalMETBEPt', 'O'), ('qCalMETBEPhi', 'O'), ('qCalMETBEEn', 'O'), ('qCalMETBEFOPt', 'O'), ('qCalMETBEFOPhi', 'O'), ('qCalMETBEFOEn', 'O'), ('qCalMETMPt', 'O'), ('qCalMETMPhi', 'O'), ('qCalMETMEn', 'O'), ('qSCEn', 'O'), ('qSCEta', 'O'), ('qSCPhi', 'O'), ('qSCEtaWidth', 'O'), ('qSCPhiWidth', 'O'), ('qSCEnhfEM', 'O'), ('qSCEtahfEM', 'O'), ('qSCPhihfEM', 'O'), ('qSCEn5x5', 'O'), ('qSCEta5x5', 'O'), ('qSCPhi5x5', 'O'), ('qSCEtaWidth5x5', 'O'), ('qSCPhiWidth5x5', 'O'), ('qCCEn', 'O'), ('qCCEta', 'O'), ('qCCPhi', 'O'), ('qCCEn5x5', 'O'), ('qCCEta5x5', 'O'), ('qCCPhi5x5', 'O'), ('qPhoPt', 'O'), ('qPhoEta', 'O'), ('qPhoPhi', 'O'), ('qPhoEn_', 'O'), ('qPhoe1x5_', 'O'), ('qPhoe2x5_', 'O'), ('qPhoe3x3_', 'O'), ('qPhoe5x5_', 'O'), ('qPhomaxenxtal_', 'O'), ('qPhosigmaeta_', 'O'), ('qPhosigmaIeta_', 'O'), ('qPhor1x5_', 'O'), ('qPhor2x5_', 'O'), ('qPhor9_', 'O'), ('qgedPhoPt', 'O'), ('qgedPhoEta', 'O'), ('qgedPhoPhi', 'O'), ('qgedPhoEn_', 'O'), ('qgedPhoe1x5_', 'O'), ('qgedPhoe2x5_', 'O'), ('qgedPhoe3x3_', 'O'), ('qgedPhoe5x5_', 'O'), ('qgedPhomaxenxtal_', 'O'), ('qgedPhosigmaeta_', 'O'), ('qgedPhosigmaIeta_', 'O'), ('qgedPhor1x5_', 'O'), ('qgedPhor2x5_', 'O'), ('qgedPhor9_', 'O'), ('qMuPt', 'O'), ('qMuEta', 'O'), ('qMuPhi', 'O'), ('qMuEn_', 'O'), ('qMuCh_', 'O'), ('qMuChi2_', 'O'), ('qSigmaIEta', 'O'), ('qSigmaIPhi', 'O'), ('qr9', 'O'), ('qHadOEm', 'O'), ('qdrSumPt', 'O'), ('qdrSumEt', 'O'), ('qeSCOP', 'O'), ('qecEn', 'O'), ('qEBenergy', 'O'), ('qEBtime', 'O'), ('qEBchi2', 'O'), ('qEBiEta', 'O'), ('qEBiPhi', 'O'), ('qEEenergy', 'O'), ('qEEtime', 'O'), ('qEEchi2', 'O'), ('qEEix', 'O'), ('qEEiy', 'O'), ('qESenergy', 'O'), ('qEStime', 'O'), ('qESix', 'O'), ('qESiy', 'O'), ('qHBHEenergy', 'O'), ('qHBHEtime', 'O'), ('qHBHEauxe', 'O'), ('qHBHEieta', 'O'), ('qHBHEiphi', 'O'), ('qHFenergy', 'O'), ('qHFtime', 'O'), ('qHFieta', 'O'), ('qHFiphi', 'O'), ('qPreShEn', 'O'), ('qPreShEta', 'O'), ('qPreShPhi', 'O'), ('qPreShYEn', 'O'), ('qPreShYEta', 'O'), ('qPreShYPhi', 'O'), ('pathRates', 'O'), ('pathNames', 'O'), ('subsystemQuality', 'O'), ('subsystemNames', 'O')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sample_tree.dtype  # returns meta data of AODTree_*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_sample_tree['lumiId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retuns the quantiles of feature, in this case \"qgTkEta\", in the corresponding Lumisection.\n",
    "# # Each Lumisection consists of 600 events and each events consists of several quantiles, mostly 7 quantiles.\n",
    "# a_sample_tree['qCCEn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let us Construct an Entity-to-feature matrix for each of the particles in the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all Partial flow Jet Lumisection in crab_20190624_142408 / * / * and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 254\n",
      "Number of loaded tree: 254\n"
     ]
    }
   ],
   "source": [
    "# dir_jet_good = \"cms_ml4dc(NEW)/good_data/JetHT/crab_20190624_142408/*/*\"\n",
    "dir_jet_good = \"cms_ml4dc(NEW)/good_data/JetHT/*/*/*\"\n",
    "\n",
    "path_jet_good = glob.glob(os.path.join(dir_jet_good, \"*.npy\"))\n",
    "\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_jet_good = sorted(path_jet_good, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_jet_good))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_jet_good = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_jet_good] \n",
    "print(\"Number of loaded tree:\", len(tree_jet_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 7\n",
      "Number of loaded tree: 7\n"
     ]
    }
   ],
   "source": [
    "# dir_jet_bad = \"cms_ml4dc(NEW)/bad_data/JetHT/crab_20190704_104137/*/*\"  \n",
    "dir_jet_bad = \"cms_ml4dc(NEW)/bad_data/JetHT/*/*/*\"\n",
    "\n",
    "path_jet_bad = glob.glob(os.path.join(dir_jet_bad, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_jet_bad = sorted(path_jet_bad, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_jet_bad))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_jet_bad = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_jet_bad] \n",
    "print(\"Number of loaded tree:\", len(tree_jet_bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A General Description of each *.npy file\n",
    "\n",
    "Each file is a \"Tree\" and each Tree consisted of 600 Lumisections -- Prevoiusly it was 200 events. \n",
    "Now the questions is which Lumisection, or how many events should be taken into accont?\n",
    "\n",
    "To answer this question, I proposed to take a look at some statistics of each lumisection. \n",
    "A good criterion to estimate the characteristics of each lumisection would be standard deviations and the mean of each feature per each lumisection.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good JetHT: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_jet_good:\n",
    "#     print(\"Tree Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in JETHT_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Tree :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"In compatibilty in A Tree File!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad JetHT: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_jet_bad:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in JETHT_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Tree :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Different Number of quantiles in the Same event!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consideration\n",
    "\n",
    "Not nly the standard deviation of lumisections are rather high for some features but it seems as if there are inconsistencies in data collections. \n",
    "As we can see in the above in \"tree_jet[24]['qPUEvt']\" the dimension of the quantile is 4 instead of 7. \n",
    "\n",
    "\n",
    "\n",
    "If the standard deviation was not high, and we would take the first lumisection of each tree to construct the entity-to-feature matrix for further analysis and this could decrease the dimensionality of data and consequently speed up the computation-- however, it is not possible!\n",
    "\n",
    "I THINK we should take into account each individual lumisection as an entity (observation) and form the entity-to-feature matrix with the following form:\n",
    "\n",
    "\n",
    "\n",
    "$Y \\in \\mathbb{R}^{N \\times V}$:\n",
    "\n",
    "|Number  |AODTree 1-tree-feature 1(1\\times7) | AODTree 1-tree-feature 2(1\\times7)| ... |lumisection-tree-feature V(1\\times7)|\n",
    "|-----|------------------------------|-----------------------------|----|----------------------------|\n",
    "|1    |lumisection 1-tree 1-feature 1(1\\times7)|lumisection 1-tree 1-feature 2(1\\times7)|...|lumisection 1-tree 1-feature V(1\\times7)|\n",
    "|2    |lumisection 2-tree 1-feature 1(1\\times7)|lumisection 2-tree 1-feature 2(1\\times7)|...|lumisection 2-tree 1-feature V(1\\times7)|\n",
    "|...  | ... | ...   |   ... |\n",
    "|$i$    |lumisection i-tree j-feature 1(1\\times7)|lumisection i-tree j-feature 2(1\\times7)|...|lumisection i-tree j-feature V(1\\times7)|\n",
    "|...     | ... | ...   |   ... |\n",
    "|N    |lumisection N-tree M-feature 1(1\\times7)|lumisection N-tree M-feature 2(1\\times7)|...|lumisection N-tree M-feature V(1\\times7)|\n",
    "\n",
    "\n",
    "Where $N$ is the number of all \"TreefFiles\" in a crab \\times all the number of lumisections in a tree file. \n",
    "With such a setting we will be able to clusterize the data regarding the lumisections of the entire run at lumisection level.\n",
    "\n",
    "I DON'T KNOW HOW PREVOUSE RESEARCHES APPROACHED THIS PROBLEM AND I AM SO CURIOUS ABOUT IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good X_jet Feature selection and converitng to numpy proper format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_jet_good, y_jet_good, inconsistencies_jet_good = prepare_array_all_events(files=tree_jet_good,\n",
    "                                                                            paths = path_jet_good,\n",
    "                                                                            features=JETHT_FEATURES,\n",
    "                                                                            data_type='good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "\n",
    "To access the inconsistence lumisection, features and other info, one should iterate over the XXX_YY_inconsistencies dict and select those values which the length of the features list is equa to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (152400, 172) (152400,)\n",
      " \n",
      "Final Shapes: X: (138280, 172)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_jet_good.shape, y_jet_good.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_jet_good = X_jet_good[~(X_jet_good==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_good = np.where(~X_jet_good.any(axis=0))[0]  # rows' index with all zeros\n",
    "Nj, Vj = final_X_jet_good.shape  \n",
    "# final_y_jet_good = np.repeat(1, final_X_jet_good.shape[0])  # removing y_jet zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_jet_good.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/JETHT_inconsistencies_good_data.txt\", 'w') as fp:\n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_jet_good.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad X_jet Feature selection and converitng to numpy proper format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_jet_bad, y_jet_bad, inconsistencies_jet_bad = prepare_array_all_events(files=tree_jet_bad,\n",
    "                                                                         paths= path_jet_bad,\n",
    "                                                                         features=JETHT_FEATURES,\n",
    "                                                                         data_type='bad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/JETHT_inconsistencies_bad_data.txt\", 'w') as fp:\n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_jet_bad.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (4200, 172) (4200,)\n",
      " \n",
      "Final Shapes: X: (1881, 172)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_jet_bad.shape, y_jet_bad.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_jet_bad = X_jet_bad[~(X_jet_bad==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_bad = np.where(~X_jet_bad.any(axis=0))[0]  # rows' index with all zeros\n",
    "Njb, Vjb = final_X_jet_bad.shape  \n",
    "# final_y_jet_bad = np.repeat(1, final_X_jet_bad.shape[0])  # removing y_jet zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_jet_bad.shape, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of each column (each feature) in X_jet Good and Bad data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = final_X_jet_good.shape\n",
    "# for i in range(c-4):\n",
    "#     feature = i // 7\n",
    "#     colum_of_the_feature = i%7\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_jet_good[:, i], ) # histtype='step', color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Good JetHT feature: \"+ JETHT_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_jet_bad[:, i], ) # histtype='step', color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Bad JetHT feature: \"+ JETHT_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of every 7 columns (each channel?) in X_jet Good and Bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = final_X_jet_good.shape\n",
    "# interval = 0\n",
    "# for i in range(len(JETHT_FEATURES)):\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_jet_good[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Good JetHT feature: \"+ JETHT_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15\n",
    "    \n",
    "#     plt.text(0.1, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_jet_good[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_jet_good[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "    \n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "#     plt.grid(True)\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_jet_bad[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Bad JetHT feature: \"+ JETHT_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.6, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_jet_bad[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_jet_bad[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "    \n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     interval += 7\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "# #     plt.savefig(\"figures/\" + 'JetHT-' +JETHT_FEATURES[i], bbox_inches = \"tight\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Array Regarding the luminosity and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140161, 172) (140161, 172)\n",
      "cnst feature free: (140161, 172)\n"
     ]
    }
   ],
   "source": [
    "JetHT = np.concatenate((final_X_jet_good, final_X_jet_bad), axis=0)\n",
    "JetHTs = JetHT[JetHT[:, -3].argsort()]  # sorting regarding luminosites\n",
    "print(JetHT.shape, JetHTs.shape)\n",
    "\n",
    "_, _, JetHTsZ, _, _, _, cnst_features_JetHT = data_normalization.preprocess_Y(Yin=JetHTs, nscf={})\n",
    "\n",
    "print(\"cnst feature free:\", JetHTsZ.shape)\n",
    "\n",
    "np.save(\"matrices/JetHT.npy\", JetHT)\n",
    "np.save(\"matrices/JetHTs.npy\", JetHTs)\n",
    "np.save(\"matrices/JetHTZ.npy\", JetHTsZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Sorted Data to Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Splitting the data into train, validation and test sets\n",
    "y = JetHTs[:, -1]\n",
    "JetHTs_train, JetHTs_test, JetHTs_y_train, JetHTs_y_test = train_test_split(JetHTsZ, y, test_size=0.2, random_state=123, shuffle=False)\n",
    "JetHTs_train, JetHTs_val, JetHTs_y_train, JetHTs_y_val = train_test_split(JetHTs_train, JetHTs_y_train, test_size=0.2, random_state=123, shuffle=False)\n",
    "\n",
    "np.save(\"matrices/JetHTs_train\", JetHTs_train)\n",
    "np.save(\"matrices/JetHTs_y_train\", JetHTs_y_train)\n",
    "np.save(\"matrices/JetHTs_val.npy\", JetHTs_val)\n",
    "np.save(\"matrices/JetHTs_y_val\", JetHTs_y_val)\n",
    "np.save(\"matrices/JetHTs_test\", JetHTs_test)\n",
    "np.save(\"matrices/JetHTs_y_test\", JetHTs_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28033, 172)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JetHTs_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Data to Train, Validation and Test sets with control on the amount of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_good_c = final_X_jet_good[:, -1]\n",
    "\n",
    "# JetHTc_train_good, JetHTc_test_good, JetHTc_y_train_good, JetHTc_y_test_good = train_test_split(\n",
    "#     final_X_jet_good, y_good_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# JetHTc_train_good, JetHTc_val_good, JetHTc_y_train_good, JetHTc_y_val_good = train_test_split(\n",
    "#     JetHTc_train_good, JetHTc_y_train_good, test_size=0.2, random_state=123)\n",
    "\n",
    "# y_bad_c = final_X_jet_bad[:, -1]\n",
    "# JetHTc_train_bad, JetHTc_test_bad, JetHTc_y_train_bad, JetHTc_y_test_bad = train_test_split(\n",
    "#     final_X_jet_bad, y_bad_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# JetHTc_train_bad, JetHTc_val_bad, JetHTc_y_train_bad, JetHTc_y_val_bad = train_test_split(\n",
    "#     JetHTc_train_bad, JetHTc_y_train_bad, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JetHTc_train = np.concatenate((JetHTc_train_good, JetHTc_train_bad), axis=0)\n",
    "# JetHTc_val = np.concatenate((JetHTc_val_good, JetHTc_val_bad), axis=0)\n",
    "# JetHTc_test = np.concatenate((JetHTc_test_good, JetHTc_test_bad), axis=0)\n",
    "\n",
    "\n",
    "# JetHTc_y_train = np.concatenate((JetHTc_y_train_good, JetHTc_y_train_bad), axis=0)\n",
    "# JetHTc_y_val = np.concatenate((JetHTc_y_val_good, JetHTc_y_val_bad), axis=0)\n",
    "# JetHTc_y_test = np.concatenate((JetHTc_y_test_good, JetHTc_y_test_bad), axis=0)\n",
    "\n",
    "# _, _, JetHTc_trainZ, _, _, _, _ = data_normalization.preprocess_Y(Yin=JetHTc_train, nscf={})\n",
    "# _, _, JetHTc_valZ, _, _, _, _ = data_normalization.preprocess_Y(Yin=JetHTc_val, nscf={})\n",
    "# _, _, JetHTc_testZ, _, _, _, _ = data_normalization.preprocess_Y(Yin=JetHTc_test, nscf={})\n",
    "\n",
    "\n",
    "# np.save(\"matrices/JetHTc_train\", JetHTc_train)\n",
    "# np.save(\"matrices/JetHTc_y_train\", JetHTc_y_train)\n",
    "# np.save(\"matrices/JetHTc_val.npy\", JetHTc_val)\n",
    "# np.save(\"matrices/JetHTc_y_val\", JetHTc_y_val)\n",
    "# np.save(\"matrices/JetHTc_test\", JetHTc_test)\n",
    "# np.save(\"matrices/JetHTc_y_test\", JetHTc_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all Single Muon Lumisection in all crabs and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 304\n",
      "Number of loaded tree: 304\n"
     ]
    }
   ],
   "source": [
    "dir_muon_good = \"cms_ml4dc(NEW)/good_data/SingleMuon/*/*/*/\"\n",
    "# dir_muon_good = \"cms_ml4dc(NEW)/good_data/SingleMuon/crab_20190624_142340/190624_122348/*\"\n",
    "\n",
    "path_muon_good = glob.glob(os.path.join(dir_muon_good, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_muon_good = sorted(path_muon_good, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_muon_good))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_muon_good = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_muon_good] \n",
    "print(\"Number of loaded tree:\", len(tree_muon_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 10\n",
      "Number of loaded tree: 10\n"
     ]
    }
   ],
   "source": [
    "dir_muon_bad = \"cms_ml4dc(NEW)/bad_data/SingleMuon/*/*/*\"\n",
    "\n",
    "path_muon_bad = glob.glob(os.path.join(dir_muon_bad, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_muon_bad = sorted(path_muon_bad, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_muon_bad))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_muon_bad = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_muon_bad] \n",
    "print(\"Number of loaded tree:\", len(tree_muon_bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Single Muon: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_muon_good:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in SINGLEMUON_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Different Number of quantiles in the Same event!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Single Muon: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(304):\n",
    "#     print(\"i:\", i)\n",
    "#     print(pd.isnull(np.array(tree_muon_good[i], dtype=object)))\n",
    "#     print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_muon_bad:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in SINGLEMUON_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Different Number of quantiles in the Same event!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good Single Muon Feature selection and converitng to numpy proper format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_muon_good, y_muon_good, inconsistencies_muon_good = prepare_array_all_events(files=tree_muon_good,\n",
    "                                                                               paths=path_muon_good, \n",
    "                                                                               features=SINGLEMUON_FEATURES,\n",
    "                                                                               data_type='good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/SingleMuon_inconsistencies_good_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_muon_good.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (182400, 130) (182400,)\n",
      " \n",
      "Final Shapes: X: (152769, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_muon_good.shape, y_muon_good.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_muon_good = X_muon_good[~(X_muon_good==0).all(1)]  # removing row with all zeros\n",
    "final_X_muon_good = final_X_muon_good[np.any(~np.isnan(final_X_muon_good), axis=1)]\n",
    "final_X_muon_good = final_X_muon_good[np.any(~(np.isinf(final_X_muon_good)), axis=1)]\n",
    "\n",
    "zero_rows_good = np.where(~X_muon_good.any(axis=0))[0]  # rows' index with all zeros\n",
    "\n",
    "# final_y_muon_good = np.repeat(1, final_X_muon_good.shape[0])  # removing y_muon zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_muon_good.shape,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad Single Muon Feature selection and converitng to numpy proper format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_muon_bad, y_muon_bad, inconsistencies_muon_bad = prepare_array_all_events(files=tree_muon_bad,\n",
    "                                                                            paths=path_muon_bad,\n",
    "                                                                            features=SINGLEMUON_FEATURES,\n",
    "                                                                            data_type='bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (6000, 130) (6000,)\n",
      " \n",
      "Final Shapes: X: (2427, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_muon_bad.shape, y_muon_bad.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_muon_bad = X_muon_bad[~(X_muon_bad==0).all(1)]  # removing row with all zeros\n",
    "final_X_muon_bad = final_X_muon_bad[np.any(~np.isnan(final_X_muon_bad), axis=1)]\n",
    "final_X_muon_bad = final_X_muon_bad[np.any(~(np.isinf(final_X_muon_bad)), axis=1)]\n",
    "zero_rows_bad = np.where(~X_muon_bad.any(axis=0))[0]  # rows' index with all zeros\n",
    "# final_y_muon_bad = np.repeat(1, final_X_muon_bad.shape[0])  # removing y_muon zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_muon_bad.shape, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/SingleMuon_inconsistencies_bad_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_muon_bad.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of each column (each feature) in X_SMuon Good and Bad data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = final_X_muon_good.shape\n",
    "# for i in range(c-4):\n",
    "#     feature = i //7\n",
    "#     colum_of_the_feature = i%7\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_muon_good[:, i],)  # histtype='step' ) # color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Good muonHT feature: \"+ SINGLEMUON_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_muon_bad[:, i],)  # histtype='step,' color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Bad muonHT feature: \"+ SINGLEMUON_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of every 7 columns (each channel?) in X_SMuon Good and Bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_muon_good.shape\n",
    "# interval = 0\n",
    "# for i in range(len(SINGLEMUON_FEATURES)):\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_muon_good[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Good muon feature: \"+ SINGLEMUON_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.1, 0.7,  \"Mean: \" + \n",
    "#          str(np.mean(final_X_muon_good[:, interval: interval+7], axis=0))\n",
    "#          + \"\\n\"\n",
    "#          \"std: \" + \n",
    "#          str(np.std(final_X_muon_good[:, interval: interval+7], axis=0)),\n",
    "#          bbox=dict(facecolor='green', alpha=0.5),\n",
    "#          transform=plt.gcf().transFigure,\n",
    "#          fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "\n",
    "#     plt.grid(True)\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_muon_bad[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Bad muon feature: \"+ SINGLEMUON_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.6, 0.7,  \"Mean: \" + \n",
    "#          str(np.mean(final_X_muon_bad[:, interval: interval+7], axis=0))\n",
    "#          + \"\\n\"\n",
    "#          \"std: \" + \n",
    "#          str(np.std(final_X_muon_bad[:, interval: interval+7], axis=0)),\n",
    "#          bbox=dict(facecolor='green', alpha=0.5),\n",
    "#          transform=plt.gcf().transFigure,\n",
    "#          fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "\n",
    "    \n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     interval += 7\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "#     plt.savefig(\"figures/\" + 'Muon-' +SINGLEMUON_FEATURES[i], bbox_inches = \"tight\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Array Regarding the luminosity and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155196, 130) (155196, 130)\n",
      "cnst feature free: (155196, 123)\n"
     ]
    }
   ],
   "source": [
    "SMuon = np.concatenate((final_X_muon_good, final_X_muon_bad), axis=0)\n",
    "SMuons = SMuon[SMuon[:, -3].argsort()]  # sorting regarding luminosites\n",
    "\n",
    "print(SMuon.shape, SMuons.shape)\n",
    "\n",
    "_, _, SMuonsZ, _, _, _, cnst_features_SMuon = data_normalization.preprocess_Y(Yin=SMuons, nscf={})\n",
    "print(\"cnst feature free:\", SMuonsZ.shape)\n",
    "\n",
    "np.save(\"matrices/SMuon.npy\", SMuon)\n",
    "np.save(\"matrices/SMuons.npy\", SMuons)\n",
    "np.save(\"matrices/SMuonZ.npy\", SMuonsZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Sorted Data to Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Splitting the data into train, validation and test sets\n",
    "y = SMuons[:, -1]\n",
    "SMuons_train, SMuons_test, SMuons_y_train, SMuons_y_test = train_test_split(SMuons, y, test_size=0.2, random_state=123, shuffle=False)\n",
    "SMuons_train, SMuons_val, SMuons_y_train, SMuons_y_val = train_test_split(SMuons_train, SMuons_y_train, test_size=0.2, random_state=123, shuffle=False)\n",
    "\n",
    "np.save(\"matrices/SMuons_train\", SMuons_train)\n",
    "np.save(\"matrices/SMuons_y_train\", SMuons_y_train)\n",
    "np.save(\"matrices/SMuons_val.npy\", SMuons_val)\n",
    "np.save(\"matrices/SMuons_y_val\", SMuons_y_val)\n",
    "np.save(\"matrices/SMuons_test\", SMuons_test)\n",
    "np.save(\"matrices/SMuons_y_test\", SMuons_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Data to Train, Validation and Test sets with control on the amount of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_good_c = final_X_muon_good[:, -1]\n",
    "\n",
    "# SMuonc_train_good, SMuonc_test_good, SMuonc_y_train_good, SMuonc_y_test_good = train_test_split(\n",
    "#     final_X_muon_good, y_good_c, test_size=0.2, random_state=123,)\n",
    "\n",
    "# SMuonc_train_good, SMuonc_val_good, SMuonc_y_train_good, SMuonc_y_val_good = train_test_split(\n",
    "#     SMuonc_train_good, SMuonc_y_train_good, test_size=0.2, random_state=123)\n",
    "\n",
    "# y_bad_c = final_X_muon_bad[:, -1]\n",
    "# SMuonc_train_bad, SMuonc_test_bad, SMuonc_y_train_bad, SMuonc_y_test_bad = train_test_split(\n",
    "#     final_X_muon_bad, y_bad_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# SMuonc_train_bad, SMuonc_val_bad, SMuonc_y_train_bad, SMuonc_y_val_bad = train_test_split(\n",
    "#     SMuonc_train_bad, SMuonc_y_train_bad, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMuonc_train = np.concatenate((SMuonc_train_good, SMuonc_train_bad), axis=0)\n",
    "# SMuonc_val = np.concatenate((SMuonc_val_good, SMuonc_val_bad), axis=0)\n",
    "# SMuonc_test = np.concatenate((SMuonc_test_good, SMuonc_test_bad), axis=0)\n",
    "\n",
    "\n",
    "# SMuonc_y_train = np.concatenate((SMuonc_y_train_good, SMuonc_y_train_bad), axis=0)\n",
    "# SMuonc_y_val = np.concatenate((SMuonc_y_val_good, SMuonc_y_val_bad), axis=0)\n",
    "# SMuonc_y_test = np.concatenate((SMuonc_y_test_good, SMuonc_y_test_bad), axis=0)\n",
    "\n",
    "# _, _, SMuonc_train, _, _, _, _ = data_normalization.preprocess_Y(Yin=SMuonc_train, nscf={})\n",
    "# _, _, SMuonc_val, _, _, _, _ = data_normalization.preprocess_Y(Yin=SMuonc_val, nscf={})\n",
    "# _, _, SMuonc_test, _, _, _, _ = data_normalization.preprocess_Y(Yin=SMuonc_test, nscf={})\n",
    "\n",
    "# np.save(\"matrices/SMuonc_train\", SMuonc_train)\n",
    "# np.save(\"matrices/SMuonc_y_train\", SMuonc_y_train)\n",
    "# np.save(\"matrices/SMuonc_val.npy\", SMuonc_val)\n",
    "# np.save(\"matrices/SMuonc_y_val\", SMuonc_y_val)\n",
    "# np.save(\"matrices/SMuonc_test\", SMuonc_test)\n",
    "# np.save(\"matrices/SMuonc_y_test\", SMuonc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99324, 130)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMuons_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all EGamma Lumisection in crab_20190624_142501 and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 169\n",
      "Number of loaded tree: 169\n"
     ]
    }
   ],
   "source": [
    "dir_egamma_good = \"cms_ml4dc(NEW)/good_data/EGamma/*/*/*\"\n",
    "\n",
    "path_egamma_good = glob.glob(os.path.join(dir_egamma_good, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_egamma_good = sorted(path_egamma_good, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_egamma_good))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_egamma_good = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_egamma_good] \n",
    "print(\"Number of loaded tree:\", len(tree_egamma_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 5\n",
      "Number of loaded tree: 5\n"
     ]
    }
   ],
   "source": [
    "dir_egamma_bad = \"cms_ml4dc(NEW)/bad_data/EGamma/*/*/*\"\n",
    "\n",
    "path_egamma_bad = glob.glob(os.path.join(dir_egamma_bad, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_egamma_bad = sorted(path_egamma_bad, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_egamma_bad))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_egamma_bad = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_egamma_bad] \n",
    "print(\"Number of loaded tree:\", len(tree_egamma_bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good EGamma: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_egamma_good:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in EGAMMA_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Number of Lumisection with some mistakes!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad EGamma: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_egamma_bad:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in EGAMMA_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Number of Lumisection with some mistakes!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good EGamma Feature selection and converitng to numpy proper format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_egamma_good, y_egamma_good, inconsistencies_egamma_good = prepare_array_all_events(files=tree_egamma_good,\n",
    "                                                                                     paths=path_egamma_good, \n",
    "                                                                                     features=EGAMMA_FEATURES,\n",
    "                                                                                     data_type='good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (101400, 214) (101400,)\n",
      " \n",
      "Final Shapes: X: (87752, 214)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_egamma_good.shape, y_egamma_good.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_egamma_good = X_egamma_good[~(X_egamma_good==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_good = np.where(~X_egamma_good.any(axis=0))[0]  # rows' index with all zeros\n",
    "# final_y_egamma_good = np.repeat(1, final_X_egamma_good.shape[0])  # removing y_egamma zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_egamma_good.shape,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/Egamma_inconsistencies_good_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_egamma_good.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad EGamma Feature selection and converitng to numpy proper format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_egamma_bad, y_egamma_bad, inconsistencies_egamma_bad = prepare_array_all_events(files=tree_egamma_bad, \n",
    "                                                                                  paths=path_egamma_bad,\n",
    "                                                                                  features=EGAMMA_FEATURES,\n",
    "                                                                                  data_type='bad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qHadOEm'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EGAMMA_FEATURES[177//7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGAMMA_FEATURES[184//7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGAMMA_FEATURES[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (3000, 214) (3000,)\n",
      " \n",
      "Final Shapes: X: (1313, 214)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_egamma_bad.shape, y_egamma_bad.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_egamma_bad = X_egamma_bad[~(X_egamma_bad==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_bad = np.where(~X_egamma_bad.any(axis=0))[0]  # rows' index with all zeros\n",
    "# final_y_egamma_bad = np.repeat(1, final_X_egamma_bad.shape[0])  # removing y_egamma zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_egamma_bad.shape,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/Egamma_inconsistencies_bad_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_egamma_bad.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of each column (each feature) in X_egamma Good and Bad data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_egamma_good.shape\n",
    "# for i in range(c-3):\n",
    "#     feature = i //7\n",
    "#     colum_of_the_feature = i%7\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_egamma_good[:, i],)  # histtype='step' ) # color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Good EGamma feature: \"+ EGAMMA_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_egamma_bad[:, i],)  # histtype='step' ) # color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Bad EGamma feature: \"+ EGAMMA_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of every 7 columns (each channel?) in X_egammaGood and Bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_egamma_good.shape\n",
    "# interval = 0\n",
    "# for i in range(len(EGAMMA_FEATURES)):\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_egamma_good[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Good egammaHT feature: \"+ EGAMMA_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.1, 0.7,  \"Mean: \" + \n",
    "#          str(np.mean(final_X_egamma_good[:, interval: interval+7], axis=0))\n",
    "#          + \"\\n\"\n",
    "#          \"std: \" + \n",
    "#          str(np.std(final_X_egamma_good[:, interval: interval+7], axis=0)),\n",
    "#          bbox=dict(facecolor='green', alpha=0.5),\n",
    "#          transform=plt.gcf().transFigure,\n",
    "#          weight='bold',\n",
    "#          fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "\n",
    "    \n",
    "#     plt.grid(True)\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_egamma_bad[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Bad egammaHT feature: \"+ EGAMMA_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.6, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_egamma_bad[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_egamma_bad[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     interval += 7\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "# #     plt.savefig(\"figures/\" + 'Egamma-' + EGAMMA_FEATURES[i], bbox_inches = \"tight\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Array Regarding the luminosity and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89065, 214) (89065, 214)\n",
      "cnst feature free: (89065, 214)\n"
     ]
    }
   ],
   "source": [
    "Egamma = np.concatenate((final_X_egamma_good, final_X_egamma_bad), axis=0)\n",
    "Egammas = Egamma[Egamma[:, -3].argsort()]  # sorting regarding luminosites\n",
    "\n",
    "print(Egamma.shape, Egammas.shape)\n",
    "_, _, EgammasZ, _, _, _, cnst_features_Egamma = data_normalization.preprocess_Y(Yin=Egammas, nscf={})\n",
    "print(\"cnst feature free:\", Egammas.shape)\n",
    "\n",
    "\n",
    "np.save(\"matrices/Egamma.npy\", Egamma)\n",
    "np.save(\"matrices/Egammas.npy\", Egammas)\n",
    "np.save(\"matrices/EgammaZ.npy\", EgammasZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Sorted Data to Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Splitting the data into train, validation and test sets\n",
    "y = Egammas[:, -1]\n",
    "Egammas_train, Egammas_test, Egammas_y_train, Egammas_y_test = train_test_split(Egammas, y, test_size=0.2, random_state=123, shuffle=False)\n",
    "Egammas_train, Egammas_val, Egammas_y_train, Egammas_y_val = train_test_split(Egammas_train, Egammas_y_train, test_size=0.2, random_state=123, shuffle=False)\n",
    "\n",
    "np.save(\"matrices/Egammas_train\", Egammas_train)\n",
    "np.save(\"matrices/Egammas_y_train\", Egammas_y_train)\n",
    "np.save(\"matrices/Egammas_val.npy\", Egammas_val)\n",
    "np.save(\"matrices/Egammas_y_val\", Egammas_y_val)\n",
    "np.save(\"matrices/Egammas_test\", Egammas_test)\n",
    "np.save(\"matrices/Egammas_y_test\", Egammas_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17813, 214)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Egammas_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Data to Train, Validation and Test sets with control on the amount of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_good_c = final_X_egamma_good[:, -1]\n",
    "\n",
    "# Egammac_train_good, Egammac_test_good, Egammac_y_train_good, Egammac_y_test_good = train_test_split(\n",
    "#     final_X_egamma_good, y_good_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# Egammac_train_good, Egammac_val_good, Egammac_y_train_good, Egammac_y_val_good = train_test_split(\n",
    "#     Egammac_train_good, Egammac_y_train_good, test_size=0.2, random_state=123)\n",
    "\n",
    "# y_bad_c = final_X_egamma_bad[:, -1]\n",
    "# Egammac_train_bad, Egammac_test_bad, Egammac_y_train_bad, Egammac_y_test_bad = train_test_split(\n",
    "#     final_X_egamma_bad, y_bad_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# Egammac_train_bad, Egammac_val_bad, Egammac_y_train_bad, Egammac_y_val_bad = train_test_split(\n",
    "#     Egammac_train_bad, Egammac_y_train_bad, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egammac_train = np.concatenate((Egammac_train_good, Egammac_train_bad), axis=0)\n",
    "# Egammac_val = np.concatenate((Egammac_val_good, Egammac_val_bad), axis=0)\n",
    "# Egammac_test = np.concatenate((Egammac_test_good, Egammac_test_bad), axis=0)\n",
    "\n",
    "\n",
    "# Egammac_y_train = np.concatenate((Egammac_y_train_good, Egammac_y_train_bad), axis=0)\n",
    "# Egammac_y_val = np.concatenate((Egammac_y_val_good, Egammac_y_val_bad), axis=0)\n",
    "# Egammac_y_test = np.concatenate((Egammac_y_test_good, Egammac_y_test_bad), axis=0)\n",
    "\n",
    "# _, _, Egammac_train, _, _, _, _ = data_normalization.preprocess_Y(Yin=Egammac_train, nscf={})\n",
    "# _, _, Egammac_val, _, _, _, _ = data_normalization.preprocess_Y(Yin=Egammac_val, nscf={})\n",
    "# _, _, Egammac_test, _, _, _, _ = data_normalization.preprocess_Y(Yin=Egammac_test, nscf={})\n",
    "\n",
    "\n",
    "\n",
    "# np.save(\"matrices/Egammac_train\", Egammac_train)\n",
    "# np.save(\"matrices/Egammac_y_train\", Egammac_y_train)\n",
    "# np.save(\"matrices/Egammac_val.npy\", Egammac_val)\n",
    "# np.save(\"matrices/Egammac_y_val\", Egammac_y_val)\n",
    "# np.save(\"matrices/Egammac_test\", Egammac_test)\n",
    "# np.save(\"matrices/Egammac_y_test\", Egammac_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptoin: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all ZeroBias Lumisection in crab_20190624_142340 and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 363\n",
      "Number of loaded tree: 363\n"
     ]
    }
   ],
   "source": [
    "dir_zerobias_good = \"cms_ml4dc(NEW)/good_data/ZeroBias/*/*/*\"\n",
    "\n",
    "path_zerobias_good = glob.glob(os.path.join(dir_zerobias_good, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_zerobias_good = sorted(path_zerobias_good, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_zerobias_good))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_zerobias_good = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_zerobias_good] \n",
    "print(\"Number of loaded tree:\", len(tree_zerobias_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded paths: 8\n",
      "Number of loaded tree: 8\n"
     ]
    }
   ],
   "source": [
    "dir_zerobias_bad = \"cms_ml4dc(NEW)/bad_data/ZeroBias/*/*/*\"\n",
    "\n",
    "path_zerobias_bad = glob.glob(os.path.join(dir_zerobias_bad, \"*.npy\"))\n",
    "\n",
    "# sorting all loaded file w.r.t AODTree_x \n",
    "path_zerobias_bad = sorted(path_zerobias_bad, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]))\n",
    "\n",
    "print(\"Number of loaded paths:\", len(path_zerobias_bad))\n",
    "\n",
    "# Loading all trees:\n",
    "tree_zerobias_bad = [np.load(i, allow_pickle=True, encoding='bytes') for i in path_zerobias_bad] \n",
    "print(\"Number of loaded tree:\", len(tree_zerobias_bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good zerobias: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_zerobias_good:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in ZEROBIAS_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Different Number of quantiles in the Same event!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad zerobias: Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_counter = 0\n",
    "# for tree in tree_zerobias_bad:\n",
    "#     print(\"Lumisection Number:\", tree_counter)\n",
    "#     print(\" \")\n",
    "#     try:\n",
    "#         for feature in ZEROBIAS_FEATURES:\n",
    "#             print(\"feature:\", feature, \"Mean   :\", np.mean(tree[feature], axis=0))\n",
    "#             print(\"feature:\", feature, \"Std    :\",  np.std(tree[feature], axis=0))\n",
    "#             print(\"#tree    :\", tree_counter, \"#Events :\", len(tree[feature]), \"\")\n",
    "#             print(\" \")\n",
    "#     except:\n",
    "#         print(\"Different Number of quantiles in the Same event!\", tree_counter)\n",
    "        \n",
    "#     tree_counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good zerobias Feature selection and converitng to numpy proper format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_zerobias_good, y_zerobias_good, inconsistencies_zerobias_good = prepare_array_all_events(files=tree_zerobias_good,\n",
    "                                                                                           paths=path_zerobias_good,\n",
    "                                                                                           features=ZEROBIAS_FEATURES,\n",
    "                                                                                           data_type='good'\n",
    "                                                                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (217800, 95) (217800,)\n",
      " \n",
      "Final Shapes: X: (182982, 95)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_zerobias_good.shape, y_zerobias_good.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_zerobias_good = X_zerobias_good[~(X_zerobias_good==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_good = np.where(~X_zerobias_good.any(axis=0))[0]  # rows' index with all zeros\n",
    "# final_y_zerobias_good = np.repeat(1, final_X_zerobias_good.shape[0])  # removing y_zerobias zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_zerobias_good.shape,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/ZeroBias_inconsistencies_good_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_zerobias_good.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad zerobias Feature selection and converitng to numpy proper format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "X_zerobias_bad, y_zerobias_bad, inconsistencies_zerobias_bad = prepare_array_all_events(files=tree_zerobias_bad, \n",
    "                                                                                        paths=path_zerobias_bad,\n",
    "                                                                                        features=ZEROBIAS_FEATURES,\n",
    "                                                                                       data_type='bad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array and the corresponding label: (4800, 95) (4800,)\n",
      " \n",
      "Final Shapes: X: (1667, 95)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the array and the corresponding label:\", X_zerobias_bad.shape, y_zerobias_bad.shape,)\n",
    "print(\" \")\n",
    "\n",
    "final_X_zerobias_bad = X_zerobias_bad[~(X_zerobias_bad==0).all(1)]  # removing row with all zeros\n",
    "zero_rows_bad = np.where(~X_zerobias_bad.any(axis=0))[0]  # rows' index with all zeros\n",
    "# final_y_zerobias_bad = np.repeat(1, final_X_zerobias_bad.shape[0])  # removing y_zerobias zeros is atreeo possible\n",
    "\n",
    "print(\"Final Shapes: X:\", final_X_zerobias_bad.shape,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"Inconsistencies/ZeroBias_inconsistencies_bad_data.txt\", 'w') as fp:\n",
    "    \n",
    "#     fp.write(\"A User Friendlier version of the previous file.\")\n",
    "#     fp.write(\"\\n\")\n",
    "#     fp.write(\"The file is self-describing\")\n",
    "\n",
    "#     fp.write(2*\"\\n\")\n",
    "#     for k, v in inconsistencies_zerobias_bad.items():\n",
    "#         for kk, vv in v.items():\n",
    "#             if len(vv['Features']) != 0:\n",
    "#                 fp.write(\"File Path:\")\n",
    "#                 fp.write(k)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"RunID:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['RunID']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"Lumi:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(str(vv['Lumi']))\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 fp.write(\"LumiID:\")\n",
    "#                 fp.write(str(vv['LuminID']))\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"Features:\")\n",
    "#                 fp.write(\"\\t\")\n",
    "#                 tmp_features = ' '.join(vv['Features'])\n",
    "#                 fp.write(tmp_features)\n",
    "#                 fp.write(\"\\n\")\n",
    "#                 tmp_len_features = vv['Len_Features']\n",
    "                \n",
    "#                 for f in range(len(vv['Len_Features'])):\n",
    "#                     fp.write(\"Feature Name:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Features'][f]))\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Value:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     feature_value_to_write = \", \".join(str(\"%.3f\" % i ) for i in vv['Val_Features'][f])\n",
    "#                     fp.write(feature_value_to_write)\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(\"Length:\")\n",
    "#                     fp.write(\"\\t\")\n",
    "#                     fp.write(str(vv['Len_Features'][f]))\n",
    "#                     fp.write(\"\\n\")\n",
    "                \n",
    "#                 fp.write(\"\\n\")\n",
    "#                 fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of each column (each feature) in X_zerobias Good and Bad data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_zerobias_good.shape\n",
    "# for i in range(c-4):\n",
    "#     feature = i //7\n",
    "#     colum_of_the_feature = i%7\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "    \n",
    "#     values, bins = np.histogram(final_X_zerobias_good[:, i],)  # histtype='step' ) \n",
    "#     #evaluate the cumulative\n",
    "#     cumulative = np.cumsum(values)\n",
    "#     plt.plot(bins[:-1], cumulative, c='blue', )\n",
    "    \n",
    "#     plt.hist(final_X_zerobias_good[:, i],)  # histtype='step') # color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Good zerobiasHT feature: \"+ ZEROBIAS_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.grid(True)\n",
    "#     plt.legend([\"Hist\", \"CDF\"])\n",
    "#     plt.subplot(222)\n",
    "    \n",
    "#     values_, bins_ = np.histogram(final_X_zerobias_bad[:, i],)  # histtype='step' ) \n",
    "#     #evaluate the cumulative\n",
    "#     cumulative_ = np.cumsum(values_)\n",
    "#     plt.plot(bins_[:-1], cumulative_, c='red', )\n",
    "    \n",
    "    \n",
    "#     plt.hist(final_X_zerobias_bad[:, i],)  # histtype='step' ) # color=plt.cm.get_cmap('nipy_spectral_r'))  #color=cmp[i])\n",
    "#     plt.title(\"Bad zerobiasHT feature: \"+ ZEROBIAS_FEATURES[feature] + \n",
    "#               \", column \" + str(colum_of_the_feature+1), fontsize=13)\n",
    "#     plt.legend([\"Hist\", \"CDF\"])\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of every 7 columns (each channel?) in X_zerobias Good and Bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_zerobias_good.shape\n",
    "# interval = 0\n",
    "# for i in range(len(ZEROBIAS_FEATURES)):\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_zerobias_good[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Good zerobias feature: \"+ ZEROBIAS_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.1, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_zerobias_good[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_zerobias_good[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.0001)\n",
    "    \n",
    "#     plt.grid(True)\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_zerobias_bad[:, interval: interval+7],)  # histtype='step' ) \n",
    "#     plt.title(\"Bad zerobias feature: \"+ ZEROBIAS_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.6, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_zerobias_bad[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_zerobias_bad[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     interval += 7\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\"figures/\" + 'ZeroBias-' +ZEROBIAS_FEATURES[i],  bbox_inches = \"tight\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of all features seperately\n",
    "\n",
    "# r, c = X_zerobias_good.shape\n",
    "# interval = 0\n",
    "# for i in range(len(ZEROBIAS_FEATURES)):\n",
    "#     plt.figure(figsize=(15.5, 12.5))\n",
    "#     plt.subplot(221)\n",
    "#     plt.hist(final_X_zerobias_good[:, interval: interval+7],\n",
    "#             cumulative=True)  # histtype='step' ) \n",
    "#     plt.title(\"Good zerobiasHT feature: \"+ ZEROBIAS_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.1, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_zerobias_good[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_zerobias_good[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "    \n",
    "#     plt.grid(True)\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "    \n",
    "#     plt.subplot(222)\n",
    "#     plt.hist(final_X_zerobias_bad[:, interval: interval+7],\n",
    "#             cumulative=True)  # histtype='step' ) \n",
    "#     plt.title(\"Bad zerobiasHT feature: \"+ ZEROBIAS_FEATURES[i])  # + \", column \" + str(colum_of_the_feature), fontsize=15)\n",
    "    \n",
    "#     plt.text(0.6, 0.7,  \"Mean: \" + \n",
    "#              str(np.mean(final_X_zerobias_bad[:, interval: interval+7], axis=0))\n",
    "#              + \"\\n\"\n",
    "#              \"std: \" + \n",
    "#              str(np.std(final_X_zerobias_bad[:, interval: interval+7], axis=0)),\n",
    "#              bbox=dict(facecolor='green', alpha=0.5),\n",
    "#              transform=plt.gcf().transFigure,\n",
    "#              weight='bold',\n",
    "#              fontsize=10)\n",
    "\n",
    "#     plt.subplots_adjust(left=0.001)\n",
    "    \n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     interval += 7\n",
    "#     plt.legend(['MEAN', 'RMS', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "#     plt.savefig(\"figures/\" + 'ZeroBias-' +ZEROBIAS_FEATURES[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Array Regarding the luminosity and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184649, 95) (184649, 95)\n",
      "(184649, 95)\n"
     ]
    }
   ],
   "source": [
    "ZeroBias = np.concatenate((final_X_zerobias_good, final_X_zerobias_bad), axis=0)\n",
    "ZeroBiass = ZeroBias[ZeroBias[:, -3].argsort()]  # sorting regarding luminosites\n",
    "\n",
    "print(ZeroBias.shape, ZeroBiass.shape)\n",
    "_, _, ZeroBiassZ, _, _, _, cnst_features_ZeroBias = data_normalization.preprocess_Y(Yin=ZeroBiass, nscf={})\n",
    "print( ZeroBiass.shape)\n",
    "\n",
    "\n",
    "np.save(\"matrices/ZeroBias.npy\", ZeroBias)\n",
    "np.save(\"matrices/ZeroBiass.npy\", ZeroBiass)\n",
    "np.save(\"matrices/ZeroBiasZ.npy\", ZeroBiassZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Sorted Data to Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Splitting the data into train, validation and test sets\n",
    "y = ZeroBiass[:, -1]\n",
    "ZeroBiass_train, ZeroBiass_test, ZeroBiass_y_train, ZeroBiass_y_test = train_test_split(ZeroBiass, y, test_size=0.2, random_state=123, shuffle=False)\n",
    "ZeroBiass_train, ZeroBiass_val, ZeroBiass_y_train, ZeroBiass_y_val = train_test_split(ZeroBiass_train, ZeroBiass_y_train, test_size=0.2, random_state=123, shuffle=False)\n",
    "\n",
    "np.save(\"matrices/ZeroBiass_train\", ZeroBiass_train)\n",
    "np.save(\"matrices/ZeroBiass_y_train\", ZeroBiass_y_train)\n",
    "np.save(\"matrices/ZeroBiass_val.npy\", ZeroBiass_val)\n",
    "np.save(\"matrices/ZeroBiass_y_val\", ZeroBiass_y_val)\n",
    "np.save(\"matrices/ZeroBiass_test\", ZeroBiass_test)\n",
    "np.save(\"matrices/ZeroBiass_y_test\", ZeroBiass_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36930, 95)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZeroBiass_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiliting The Data to Train, Validation and Test sets with control on the amount of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_good_c = final_X_zerobias_good[:, -1]\n",
    "\n",
    "# ZeroBiasc_train_good, ZeroBiasc_test_good, ZeroBiasc_y_train_good, ZeroBiasc_y_test_good = train_test_split(\n",
    "#     final_X_zerobias_good, y_good_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# ZeroBiasc_train_good, ZeroBiasc_val_good, ZeroBiasc_y_train_good, ZeroBiasc_y_val_good = train_test_split(\n",
    "#     ZeroBiasc_train_good, ZeroBiasc_y_train_good, test_size=0.2, random_state=123)\n",
    "\n",
    "# y_bad_c = final_X_zerobias_bad[:, -1]\n",
    "# ZeroBiasc_train_bad, ZeroBiasc_test_bad, ZeroBiasc_y_train_bad, ZeroBiasc_y_test_bad = train_test_split(\n",
    "#     final_X_zerobias_bad, y_bad_c, test_size=0.2, random_state=123)\n",
    "\n",
    "# ZeroBiasc_train_bad, ZeroBiasc_val_bad, ZeroBiasc_y_train_bad, ZeroBiasc_y_val_bad = train_test_split(\n",
    "#     ZeroBiasc_train_bad, ZeroBiasc_y_train_bad, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZeroBiasc_train = np.concatenate((ZeroBiasc_train_good, ZeroBiasc_train_bad), axis=0)\n",
    "# ZeroBiasc_val = np.concatenate((ZeroBiasc_val_good, ZeroBiasc_val_bad), axis=0)\n",
    "# ZeroBiasc_test = np.concatenate((ZeroBiasc_test_good, ZeroBiasc_test_bad), axis=0)\n",
    "\n",
    "\n",
    "# ZeroBiasc_y_train = np.concatenate((ZeroBiasc_y_train_good, ZeroBiasc_y_train_bad), axis=0)\n",
    "# ZeroBiasc_y_val = np.concatenate((ZeroBiasc_y_val_good, ZeroBiasc_y_val_bad), axis=0)\n",
    "# ZeroBiasc_y_test = np.concatenate((ZeroBiasc_y_test_good, ZeroBiasc_y_test_bad), axis=0)\n",
    "\n",
    "\n",
    "# _, _, ZeroBiasc_train, _, _, _, _ = data_normalization.preprocess_Y(Yin=ZeroBiasc_train, nscf={})\n",
    "# _, _, ZeroBiasc_val, _, _, _, _ = data_normalization.preprocess_Y(Yin=ZeroBiasc_val, nscf={})\n",
    "# _, _, ZeroBiasc_test, _, _, _, _ = data_normalization.preprocess_Y(Yin=ZeroBiasc_test, nscf={})\n",
    "\n",
    "\n",
    "# np.save(\"matrices/ZeroBiasc_train\", ZeroBiasc_train)\n",
    "# np.save(\"matrices/ZeroBiasc_y_train\", ZeroBiasc_y_train)\n",
    "# np.save(\"matrices/ZeroBiasc_val.npy\", ZeroBiasc_val)\n",
    "# np.save(\"matrices/ZeroBiasc_y_val\", ZeroBiasc_y_val)\n",
    "# np.save(\"matrices/ZeroBiasc_test\", ZeroBiasc_test)\n",
    "# np.save(\"matrices/ZeroBiasc_y_test\", ZeroBiasc_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptoin: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go a bit further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_paths = []\n",
    "bad_run_ids = []\n",
    "bad_features = []\n",
    "bad_lumid_ids = []\n",
    "bad_feature_lengths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in inconsistencies_zerobias_bad.items():\n",
    "    for kk, vv in v.items():\n",
    "        if len(vv['Features']) != 0:\n",
    "            tmp_bad_path = '/'.join(k.split(\"/\")[2:])\n",
    "            bad_paths.append(tmp_bad_path)\n",
    "            \n",
    "            tmp_bad_feature = vv['Features']\n",
    "            bad_features.append(tmp_bad_feature)\n",
    "            \n",
    "            bad_run_ids.append([vv['RunID']])\n",
    "            \n",
    "            bad_lumid_ids.append(str(vv['LuminID']))\n",
    "            tmp_bad_features_len = vv['Len_Features']\n",
    "            bad_feature_lengths.append(tmp_bad_features_len)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_paths = []\n",
    "good_run_ids = []\n",
    "good_features = []\n",
    "good_lumid_ids = []\n",
    "good_feature_lengths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in inconsistencies_zerobias_good.items():\n",
    "    for kk, vv in v.items():\n",
    "        if len(vv['Features']) != 0:\n",
    "            tmp_good_path = '/'.join(k.split(\"/\")[2:])\n",
    "            good_paths.append(tmp_good_path)\n",
    "            \n",
    "            tmp_good_feature = vv['Features']\n",
    "            good_features.append(tmp_good_feature)\n",
    "            \n",
    "            good_run_ids.append([vv['RunID']])\n",
    "            \n",
    "            good_lumid_ids.append(str(vv['LuminID']))\n",
    "            tmp_good_features_len = vv['Len_Features']\n",
    "            good_feature_lengths.append(tmp_good_features_len)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_paths), len(bad_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_good_feature_lengths = [item for sublist in good_feature_lengths for item in sublist]\n",
    "flat_bad_feature_lengths = [item for sublist in bad_feature_lengths for item in sublist]\n",
    "\n",
    "print(len(flat_good_feature_lengths), len(flat_bad_feature_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(15.5, 12.5))\n",
    "plt.subplot(221)\n",
    "plt.hist(flat_good_feature_lengths)\n",
    "plt.title(\"Size of inconsistente features In Good Data\")\n",
    "plt.subplot(222)\n",
    "plt.hist(flat_bad_feature_lengths, color='r')\n",
    "plt.title(\"Size of inconsistente features In Bad Data\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_bad_features = [item for sublist in bad_features for item in sublist]\n",
    "flat_good_features = [item for sublist in good_features for item in sublist]\n",
    "\n",
    "\n",
    "print(len(flat_good_features), len(flat_bad_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(22.2, 15.5))\n",
    "plt.subplot(221)\n",
    "plt.hist(flat_good_features)\n",
    "plt.title(\"Name of inconsistente features In Good Data\")\n",
    "plt.xticks(rotation='vertical', fontsize=10, weight='bold')\n",
    "plt.margins(0.05)  #Pad margins so that markers don't get clipped by the axes\n",
    "plt.subplots_adjust(bottom=0.15)  # # Tweak spacing to prevent clipping of tick-labels\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(flat_bad_features, color='r')\n",
    "plt.title(\"Name of inconsistente features In Bad Data\")\n",
    "plt.xticks(rotation='vertical', fontsize=10, weight='bold')\n",
    "plt.margins(0.05)  #Pad margins so that markers don't get clipped by the axes\n",
    "plt.subplots_adjust(bottom=0.15)  # # Tweak spacing to prevent clipping of tick-labels\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_bad_run_id  = [item for sublist in bad_run_ids for item in sublist]\n",
    "flat_good_run_id = [item for sublist in good_run_ids for item in sublist]\n",
    "\n",
    "print(len(flat_good_run_id), len(flat_bad_run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(22.2, 15.5))\n",
    "plt.subplot(221)\n",
    "plt.hist(flat_good_run_id)\n",
    "plt.title(\"Run ID of inconsistente features In Good Data\")\n",
    "plt.xticks(rotation='vertical', fontsize=10, weight='bold')\n",
    "plt.margins(0.05)  #Pad margins so that markers don't get clipped by the axes\n",
    "plt.subplots_adjust(bottom=0.15)  # # Tweak spacing to prevent clipping of tick-labels\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(flat_bad_run_id, color='r')\n",
    "plt.title(\"Run ID of inconsistente features In Bad Data\")\n",
    "plt.xticks(rotation='vertical', fontsize=10, weight='bold')\n",
    "plt.margins(0.05)  #Pad margins so that markers don't get clipped by the axes\n",
    "plt.subplots_adjust(bottom=0.15)  # # Tweak spacing to prevent clipping of tick-labels\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_zerobias_good.shape, final_X_zerobias_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_muon_good.shape, final_X_muon_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_egamma_good.shape, final_X_egamma_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_jet_good.shape, final_X_jet_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An inconsistent sample with more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sample_tree = np.load('cms_ml4dc(NEW)/good_data/JetHT/crab_20190702_114812/190702_094816/0000/AODTree_2.npy', allow_pickle=True, encoding='bytes')\n",
    "print(\"Number of Events in a Lumisection:\", a_sample_tree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sample_tree.dtype  # returns meta data of AODTree_*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sample_tree['lumi'][89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_feature = False\n",
    "features = JETHT_FEATURES\n",
    "for feature in range(len(features)): \n",
    "    if len(a_sample_tree[features[feature]].tolist()) != 7: \n",
    "        bad_feature = True\n",
    "        print(feature, features[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(a_sample_tree['qlumiEvt'].shape[0]):\n",
    "    if len(a_sample_tree['qlumiEvt'][i]) != 7:\n",
    "        print(a_sample_tree['lumiId'][i-1], a_sample_tree['lumi'][i-1], a_sample_tree['qlumiEvt'][i-1], )\n",
    "        print(a_sample_tree['lumiId'][i], a_sample_tree['lumi'][i], a_sample_tree['qlumiEvt'][i],  )\n",
    "        print(a_sample_tree['lumiId'][i+1], a_sample_tree['lumi'][i+1], a_sample_tree['qlumiEvt'][i+1],)\n",
    "    c += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
