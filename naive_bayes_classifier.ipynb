{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython import embed\n",
    "from sklearn import datasets\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils.fixes import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFNaiveBayesClassifier:\n",
    "    dist = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Seperate training points by class (nb_classes * nv_samples * nb_features)\n",
    "        unique_y = np.unique(y)\n",
    "        points_by_class = np.array([\n",
    "            [x for x, t in zip(X, y) if t==c ]\n",
    "            for c in unique_y\n",
    "        ])\n",
    "        \n",
    "        # Estimate mean and variance for each class/feature\n",
    "        # shape: nb_classes * nb_features\n",
    "        mean, var = tf.nn.moments(tf.constant(points_by_class), axes=[1])\n",
    "\n",
    "        # Create a 3x2 univariate normal distribution with \n",
    "        # known mean and variance \n",
    "        self.dist = tf.compat.v1.distributions.Normal(loc=mean, scale=tf.sqrt(var))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        assert self.dist is not None\n",
    "        \n",
    "        nb_classes, nb_features = map(int, self.dist.scale.shape)\n",
    "        \n",
    "        # Conditional probabilities log P(X|c) with shape\n",
    "        # (nb_samples, nb_classes)\n",
    "        \n",
    "        print(\"X\", X.shape)\n",
    "        print(nb_classes)\n",
    "        print(tf.tile(X, [1, nb_classes]).shape)\n",
    "        \n",
    "        \n",
    "        cond_probs = tf.reduce_sum(self.dist.log_prob(tf.reshape(\n",
    "            tf.tile(X, [1, nb_classes]), [-1, nb_classes, nb_features])),\n",
    "                                  axis=2)\n",
    "        \n",
    "        # uniform priors\n",
    "        priors = np.log(np.array([1. / nb_classes] * nb_classes))\n",
    "        \n",
    "        # posterior log probability, log P(c) + logP(x|c)\n",
    "        \n",
    "        joint_likelihood = tf.add(priors, cond_probs)\n",
    "        \n",
    "        # normalize to get (log)-probabilities\n",
    "        norm_factor = tf.reduce_logsumexp(joint_likelihood, axis=1, keepdims=True)\n",
    "        \n",
    "        log_prob = joint_likelihood -norm_factor\n",
    "        \n",
    "        # exp to get the actual probabilities\n",
    "        return tf.exp(log_prob)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "X (900, 2)\n",
      "3\n",
      "(900, 6)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    iris = datasets.load_iris()\n",
    "    # Only take the first two features\n",
    "    X = iris.data[:, :2]\n",
    "    y = iris.target\n",
    "    print(y)\n",
    "    \n",
    "    tf_nb = TFNaiveBayesClassifier()\n",
    "    tf_nb.fit(X, y)\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 30),\n",
    "                        np.linspace(y_min, y_max, 30))\n",
    "    \n",
    "    Z = tf_nb.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z1 = Z[:, 1]\n",
    "    Z2 = Z[:, 2]\n",
    "#     print(\"z1:\", Z1)\n",
    "#     print(\"z2:\", Z2)\n",
    "\n",
    "#     # Plot\n",
    "#     fig = plt.figure(figsize=(5, 3.75))\n",
    "#     ax = fig.add_subplot(111)\n",
    "\n",
    "#     ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "#                 edgecolor='k')\n",
    "#     # Swap signs to make the contour dashed (MPL default)\n",
    "#     ax.contour(xx, yy, -Z1, [-0.5], colors='k')\n",
    "#     ax.contour(xx, yy, -Z2, [-0.5], colors='k')\n",
    "\n",
    "#     ax.set_xlabel('Sepal length')\n",
    "#     ax.set_ylabel('Sepal width')\n",
    "#     ax.set_title('TensorFlow decision boundary')\n",
    "#     ax.set_xlim(x_min, x_max)\n",
    "#     ax.set_ylim(y_min, y_max)\n",
    "#     ax.set_xticks(())\n",
    "#     ax.set_yticks(())\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_beta2",
   "language": "python",
   "name": "tf_beta2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
