{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, linewidth=150, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Visulize Y with Quantatitve features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_particle = 'JetHTc'\n",
    "\n",
    "X_train = np.load(\"matrices/\" + name_of_particle +\"_train.npy\",)\n",
    "y_train = np.load(\"matrices/\" + name_of_particle +\"_y_train.npy\",)\n",
    "X_val = np.load(\"matrices/\" + name_of_particle +\"_val.npy\",)\n",
    "y_val = np.load(\"matrices/\" + name_of_particle +\"_y_val.npy\",)\n",
    "X_test = np.load(\"matrices/\" + name_of_particle +\"_test.npy\",)\n",
    "y_test = np.load(\"matrices/\" + name_of_particle +\"_y_test.npy\",)\n",
    "X_train = X_train[:, :-3]\n",
    "X_val = X_val[:, :-3]\n",
    "X_test = X_test[:, :-3]\n",
    "_, V = X_train.shape\n",
    "K = 2\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_true, y_pred):\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    FSCORE = np.divide((2*PPV*TPR), (PPV+TPR))\n",
    "    \n",
    "    return PPV, TPR, FSCORE, FNR, FPR, TNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demonstrating the created data sets - Without Noise\n",
    "\n",
    "Let us compute the PCA of each case and plot the first two principle components. Moreover, we plo the image plot of the corresponding entity-to-feature matrix next to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALLY BLANK\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spilitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [-1 if i ==1 else 1 for i in y_test]\n",
    "y_train = [-1 if i ==1 else 1 for i in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-1, 1}, {-1, 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test), set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Class SVM\n",
    "\n",
    "nu=0.1, kernel=\"rbf\", gamma=0.1   >>  precision-OCS: 0.00 recall-kmean: 0.00 fscore-kmean: 0.00, 4h 54min 31s\n",
    "\n",
    "nu=0.01, kernel=\"rbf\", gamma=auto, shrinking=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 'scale')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = [0.01,]  # 0.1, 0.5, 0.9]\n",
    "gamma = ['scale']\n",
    "setting_ocs = list(itertools.product(nu, gamma))\n",
    "setting_ocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train setting: (0.01, 'scale')\n",
      "precision-OCS: 0.97 recall: 0.98 fscore: 0.98\n",
      " \n",
      "test\n",
      "precision-OCS: 0.97 recall: 0.98 fscore: 0.98\n",
      "62.25480532646179\n"
     ]
    }
   ],
   "source": [
    "for i in setting_ocs:\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"train setting:\", i)\n",
    "    \n",
    "    clf_ocs =  svm.OneClassSVM(nu=i[0], kernel=\"rbf\", gamma=i[1], shrinking=True)\n",
    "    clf_ocs.fit(X_train)\n",
    "    labels_pred_ocs_train = clf_ocs.predict(X_train)\n",
    "    labels_pred_ocs = clf_ocs.predict(X_test)\n",
    "\n",
    "    with open (os.path.join('RealData_computation', \"clustering_ocs_Zero\" + str(i) +\".pickle\"), 'wb') as fp:  # Small_Quantatitive\n",
    "        pickle.dump(clf_ocs, fp)  \n",
    "    \n",
    "#     AMI_ocs = metrics.adjusted_mutual_info_score(y_train, labels_pred_ocs_train)\n",
    "#     NMI_ocs = metrics.normalized_mutual_info_score(y_train, labels_pred_ocs_train)\n",
    "#     ARI_ocs = metrics.adjusted_rand_score(y_train, labels_pred_ocs_train)\n",
    "    FSCORE_ocs = precision_recall_fscore_support(y_train, labels_pred_ocs_train, average='weighted')\n",
    "    \n",
    "    \n",
    "    print(\"precision-OCS:\", \"%.2f\" % FSCORE_ocs[0], \"recall:\", \"%.2f\" % FSCORE_ocs[1], \"fscore:\", \"%.2f\" % FSCORE_ocs[2])\n",
    "    print(\" \")\n",
    "    \n",
    "    \n",
    "#     AMI_ocs_test = metrics.adjusted_mutual_info_score(y_test, labels_pred_ocs)\n",
    "#     NMI_ocs_test = metrics.normalized_mutual_info_score(y_test, labels_pred_ocs)\n",
    "#     ARI_ocs_test = metrics.adjusted_rand_score(y_test, labels_pred_ocs)\n",
    "    FSCORE_ocs_test = precision_recall_fscore_support(y_test, labels_pred_ocs, average='weighted')\n",
    "    print(\"test\")\n",
    "    print(\"precision-OCS:\", \"%.2f\" % FSCORE_ocs_test[0], \"recall:\", \"%.2f\" % FSCORE_ocs_test[1], \"fscore:\", \"%.2f\" % FSCORE_ocs_test[2])\n",
    "    \n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    \n",
    "    PPV, TPR, FSCORE, FNR, FPR, TNR = perf_measure(y_true=y_test, y_pred=labels_pred_ocs)\n",
    "    \n",
    "    PPV, TPR, FSCORE, FNR, FPR, TNR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.06, 0.99]),\n",
       " array([0.05, 0.99]),\n",
       " array([0.05, 0.99]),\n",
       " array([0.95, 0.01]),\n",
       " array([0.01, 0.95]),\n",
       " array([0.99, 0.05]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPV, TPR, FSCORE, FNR, FPR, TNR = perf_measure(y_true=y_test, y_pred=labels_pred_ocs)\n",
    "    \n",
    "PPV, TPR, FSCORE, FNR, FPR, TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in setting_ocs:\n",
    "#     print(\"test\", \"setting:\", i)\n",
    "    \n",
    "#     with open (os.path.join('RealData_computation', \"clustering_ocs\" + str(i) +\".pickle\"), 'rb') as fp:  # Small_Quantatitive\n",
    "#         clf_ocs = pickle.load(fp)  \n",
    "        \n",
    "    \n",
    "#     labels_pred_ocs = clf_ocs.predict(X_test)\n",
    "    \n",
    "    \n",
    "#     FSCORE_ocs_test = precision_recall_fscore_support(y_test, labels_pred_ocs, average='weighted')\n",
    "    \n",
    "#     print(\"precision-OCS:\", \"%.2f\" % FSCORE_ocs_test[0], \"recall:\", \"%.2f\" % FSCORE_ocs_test[1], \"fscore:\", \"%.2f\" % FSCORE_ocs_test[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   17,   360],\n",
       "       [  260, 27396]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_ven",
   "language": "python",
   "name": "tf_ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
