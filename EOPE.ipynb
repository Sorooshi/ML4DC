{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(tf.__version__)\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_true, y_pred):\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    FSCORE = np.divide((2*PPV*TPR), (PPV+TPR))\n",
    "    \n",
    "    return PPV, TPR, FSCORE, FNR, FPR, TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_particle = 'Egammac'\n",
    "\n",
    "X_train = np.load(\"matrices/\" + name_of_particle +\"_train.npy\",).astype('float32')\n",
    "y_train = np.load(\"matrices/\" + name_of_particle +\"_y_train.npy\",).astype('float32')\n",
    "X_val = np.load(\"matrices/\" + name_of_particle +\"_val.npy\",).astype('float32')\n",
    "y_val = np.load(\"matrices/\" + name_of_particle +\"_y_val.npy\",).astype('float32')\n",
    "X_test = np.load(\"matrices/\" + name_of_particle +\"_test.npy\",).astype('float32')\n",
    "y_test = np.load(\"matrices/\" + name_of_particle +\"_y_test.npy\",).astype('float32')\n",
    "X_train = X_train[:, :-3]\n",
    "X_val = X_val[:, :-3]\n",
    "X_test = X_test[:, :-3]\n",
    "N, V = X_train.shape\n",
    "K = 1\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_min = np.min(X_train, keepdims=True, axis=0)\n",
    "supp_max = np.max(X_train, keepdims=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)  #.shuffle(1000)  \n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size) #.shuffle(1000)  #shuffle(1000)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)  #.shuffle(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(OccModel, self).__init__()\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(256, input_shape=(V,),\n",
    "                                            kernel_initializer='uniform', name='dense1')\n",
    "        \n",
    "        self.dense2 = tf.keras.layers.Dense(32,\n",
    "                                           kernel_initializer='uniform',\n",
    "                                            name='dense2')\n",
    "        \n",
    "        self.pred_layer = tf.keras.layers.Dense(1, activation='linear',\n",
    "                                           kernel_initializer='uniform', \n",
    "                                                name='predictions')   \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.pred_layer(x)\n",
    "    \n",
    "\n",
    "model_occ = OccModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_monte_carlo(num_samples, N_pos, model):\n",
    "    \n",
    "    sum_samples = 0\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        \n",
    "        x_pseudo = tf.random.uniform(shape=[N_pos, V],\n",
    "                                     minval=supp_min, maxval=supp_max,\n",
    "                                     dtype='float32',)\n",
    "                \n",
    "        sum_samples += tf.reduce_mean(model(x_pseudo))\n",
    "    \n",
    "    return (supp_max - supp_min) * (sum_samples/num_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy-Base OPE\n",
    "\n",
    "#### Creating the custom loss function for training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_bf(model, X_tr, y_tr, x_pos, x_neg): \n",
    "        \n",
    "    N_pos, _ = x_pos.shape\n",
    "    \n",
    "    p_pos = model(x_pos)\n",
    "    p_neg = model(x_neg)\n",
    "    \n",
    "    N_pos, V = x_pos.shape\n",
    "    N_neg, _ = x_neg.shape\n",
    "    \n",
    "    p_psedo = crude_monte_carlo(num_samples=100, N_pos=N_pos, model=model)\n",
    "    \n",
    "    loss_pos = N_pos / (N_pos + N_neg) * tf.reduce_mean(tf.nn.softplus(-p_pos))\n",
    "    loss_neg = N_neg / (N_pos + N_neg) * tf.reduce_mean(tf.nn.softplus(p_neg)) \n",
    "    loss_pseudo = 0.001 * tf.reduce_mean(p_psedo)\n",
    "    \n",
    "    preds = tf.nn.sigmoid(model_occ(X_tr))\n",
    "    \n",
    "    return loss_pos + loss_neg + loss_pseudo, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosing an optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy() \n",
    "optimizer = tf.keras.optimizers.Adam(1e-6) # 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics to measure the loss and accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss') \n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (*)\n",
    "@tf.function\n",
    "def train_step(X_tr, y_tr, x_pos, x_neg): \n",
    "    with tf.GradientTape() as tape:  # Record operations for automatic differentiation\n",
    "        loss, preds = loss_bf(model=model_occ, X_tr=X_tr, y_tr=y_tr, x_pos=x_pos, x_neg=x_neg)  # x_pos=x_pos, x_neg=x_neg, x_pseudo=x_pseudo\n",
    "        # y_tr = tf.reshape(tf.tile(y_tr, [2]), [-1, 2])\n",
    "        loss_ = loss_object(y_tr, preds)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model_occ.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model_occ.trainable_variables))\n",
    "    \n",
    "    train_loss(loss_)\n",
    "    train_accuracy(y_tr, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(X, labels):\n",
    "    predictions = model_occ(X)\n",
    "#     labels = tf.reshape(tf.tile(labels, [2]), [-1, 2])\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.693, Train Accuracy:53.888,     Validation Loss: 0.182, Validation Accuracy:98.244,\n",
      "Epoch 2, Train Loss: 0.693, Train Accuracy:52.978,     Validation Loss: 0.180, Validation Accuracy:98.244,\n",
      "Epoch 3, Train Loss: 0.694, Train Accuracy:52.024,     Validation Loss: 0.179, Validation Accuracy:98.244,\n",
      "Epoch 4, Train Loss: 0.694, Train Accuracy:51.159,     Validation Loss: 0.178, Validation Accuracy:98.244,\n",
      "Epoch 5, Train Loss: 0.694, Train Accuracy:50.329,     Validation Loss: 0.173, Validation Accuracy:98.244,\n",
      "Epoch 6, Train Loss: 0.694, Train Accuracy:49.490,     Validation Loss: 0.173, Validation Accuracy:98.244,\n",
      "Epoch 7, Train Loss: 0.695, Train Accuracy:48.728,     Validation Loss: 0.171, Validation Accuracy:98.244,\n",
      "Epoch 8, Train Loss: 0.695, Train Accuracy:48.053,     Validation Loss: 0.168, Validation Accuracy:98.244,\n",
      "Epoch 9, Train Loss: 0.695, Train Accuracy:47.494,     Validation Loss: 0.166, Validation Accuracy:98.244,\n",
      "Epoch 10, Train Loss: 0.695, Train Accuracy:46.869,     Validation Loss: 0.164, Validation Accuracy:98.244,\n",
      "Epoch 11, Train Loss: 0.695, Train Accuracy:46.421,     Validation Loss: 0.162, Validation Accuracy:98.244,\n",
      "Epoch 12, Train Loss: 0.696, Train Accuracy:45.980,     Validation Loss: 0.161, Validation Accuracy:98.244,\n",
      "Epoch 13, Train Loss: 0.696, Train Accuracy:45.546,     Validation Loss: 0.162, Validation Accuracy:98.244,\n",
      "Epoch 14, Train Loss: 0.696, Train Accuracy:45.194,     Validation Loss: 0.162, Validation Accuracy:98.244,\n",
      "Epoch 15, Train Loss: 0.697, Train Accuracy:44.883,     Validation Loss: 0.166, Validation Accuracy:98.244,\n",
      "Epoch 16, Train Loss: 0.697, Train Accuracy:44.608,     Validation Loss: 0.169, Validation Accuracy:98.244,\n",
      "Epoch 17, Train Loss: 0.697, Train Accuracy:44.313,     Validation Loss: 0.167, Validation Accuracy:98.244,\n",
      "Epoch 18, Train Loss: 0.698, Train Accuracy:44.116,     Validation Loss: 0.168, Validation Accuracy:98.244,\n",
      "Epoch 19, Train Loss: 0.698, Train Accuracy:43.900,     Validation Loss: 0.169, Validation Accuracy:98.244,\n",
      "Epoch 20, Train Loss: 0.698, Train Accuracy:43.701,     Validation Loss: 0.171, Validation Accuracy:98.244,\n",
      "Epoch 21, Train Loss: 0.699, Train Accuracy:43.532,     Validation Loss: 0.174, Validation Accuracy:98.244,\n",
      "Epoch 22, Train Loss: 0.699, Train Accuracy:43.334,     Validation Loss: 0.176, Validation Accuracy:98.244,\n",
      "Epoch 23, Train Loss: 0.700, Train Accuracy:43.229,     Validation Loss: 0.176, Validation Accuracy:98.244,\n",
      "Epoch 24, Train Loss: 0.700, Train Accuracy:43.142,     Validation Loss: 0.179, Validation Accuracy:98.244,\n",
      "Epoch 25, Train Loss: 0.700, Train Accuracy:43.032,     Validation Loss: 0.182, Validation Accuracy:98.244,\n",
      "Epoch 26, Train Loss: 0.701, Train Accuracy:42.950,     Validation Loss: 0.182, Validation Accuracy:98.244,\n",
      "Epoch 27, Train Loss: 0.701, Train Accuracy:42.875,     Validation Loss: 0.186, Validation Accuracy:98.244,\n",
      "Epoch 28, Train Loss: 0.702, Train Accuracy:42.817,     Validation Loss: 0.190, Validation Accuracy:98.244,\n",
      "Epoch 29, Train Loss: 0.702, Train Accuracy:42.788,     Validation Loss: 0.192, Validation Accuracy:98.237,\n",
      "Epoch 30, Train Loss: 0.703, Train Accuracy:42.774,     Validation Loss: 0.195, Validation Accuracy:98.237,\n",
      "Epoch 31, Train Loss: 0.704, Train Accuracy:42.791,     Validation Loss: 0.198, Validation Accuracy:98.237,\n",
      "Epoch 32, Train Loss: 0.704, Train Accuracy:42.758,     Validation Loss: 0.201, Validation Accuracy:98.237,\n",
      "Epoch 33, Train Loss: 0.705, Train Accuracy:42.725,     Validation Loss: 0.205, Validation Accuracy:98.237,\n",
      "Epoch 34, Train Loss: 0.705, Train Accuracy:42.734,     Validation Loss: 0.210, Validation Accuracy:98.230,\n",
      "Epoch 35, Train Loss: 0.706, Train Accuracy:42.720,     Validation Loss: 0.215, Validation Accuracy:98.230,\n",
      "Epoch 36, Train Loss: 0.707, Train Accuracy:42.680,     Validation Loss: 0.219, Validation Accuracy:98.223,\n",
      "Epoch 37, Train Loss: 0.708, Train Accuracy:42.680,     Validation Loss: 0.224, Validation Accuracy:98.216,\n",
      "Epoch 38, Train Loss: 0.708, Train Accuracy:42.725,     Validation Loss: 0.229, Validation Accuracy:98.188,\n",
      "Epoch 39, Train Loss: 0.709, Train Accuracy:42.739,     Validation Loss: 0.233, Validation Accuracy:98.146,\n",
      "Epoch 40, Train Loss: 0.710, Train Accuracy:42.788,     Validation Loss: 0.236, Validation Accuracy:98.101,\n",
      "Epoch 41, Train Loss: 0.711, Train Accuracy:42.851,     Validation Loss: 0.240, Validation Accuracy:98.025,\n",
      "Epoch 42, Train Loss: 0.712, Train Accuracy:42.864,     Validation Loss: 0.244, Validation Accuracy:97.920,\n",
      "Epoch 43, Train Loss: 0.713, Train Accuracy:42.884,     Validation Loss: 0.248, Validation Accuracy:97.718,\n",
      "Epoch 44, Train Loss: 0.714, Train Accuracy:42.924,     Validation Loss: 0.251, Validation Accuracy:97.564,\n",
      "Epoch 45, Train Loss: 0.715, Train Accuracy:42.946,     Validation Loss: 0.256, Validation Accuracy:97.404,\n",
      "Epoch 46, Train Loss: 0.716, Train Accuracy:42.922,     Validation Loss: 0.260, Validation Accuracy:97.187,\n",
      "Epoch 47, Train Loss: 0.717, Train Accuracy:42.974,     Validation Loss: 0.266, Validation Accuracy:96.881,\n",
      "Epoch 48, Train Loss: 0.718, Train Accuracy:42.997,     Validation Loss: 0.271, Validation Accuracy:96.536,\n",
      "Epoch 49, Train Loss: 0.719, Train Accuracy:43.033,     Validation Loss: 0.277, Validation Accuracy:96.165,\n",
      "Epoch 50, Train Loss: 0.720, Train Accuracy:43.014,     Validation Loss: 0.283, Validation Accuracy:95.713,\n",
      "Epoch 51, Train Loss: 0.721, Train Accuracy:43.019,     Validation Loss: 0.289, Validation Accuracy:95.205,\n",
      "Epoch 52, Train Loss: 0.723, Train Accuracy:42.981,     Validation Loss: 0.295, Validation Accuracy:94.768,\n",
      "Epoch 53, Train Loss: 0.724, Train Accuracy:42.976,     Validation Loss: 0.302, Validation Accuracy:94.216,\n",
      "Epoch 54, Train Loss: 0.725, Train Accuracy:42.983,     Validation Loss: 0.309, Validation Accuracy:93.612,\n",
      "Epoch 55, Train Loss: 0.727, Train Accuracy:43.016,     Validation Loss: 0.318, Validation Accuracy:92.983,\n",
      "Epoch 56, Train Loss: 0.728, Train Accuracy:43.060,     Validation Loss: 0.329, Validation Accuracy:92.298,\n",
      "Epoch 57, Train Loss: 0.730, Train Accuracy:43.094,     Validation Loss: 0.337, Validation Accuracy:91.687,\n",
      "Epoch 58, Train Loss: 0.731, Train Accuracy:43.084,     Validation Loss: 0.350, Validation Accuracy:90.998,\n",
      "Epoch 59, Train Loss: 0.733, Train Accuracy:43.098,     Validation Loss: 0.361, Validation Accuracy:90.283,\n",
      "Epoch 60, Train Loss: 0.734, Train Accuracy:43.126,     Validation Loss: 0.377, Validation Accuracy:89.616,\n",
      "Epoch 61, Train Loss: 0.736, Train Accuracy:43.164,     Validation Loss: 0.392, Validation Accuracy:88.631,\n",
      "Epoch 62, Train Loss: 0.738, Train Accuracy:43.204,     Validation Loss: 0.411, Validation Accuracy:87.875,\n",
      "Epoch 63, Train Loss: 0.739, Train Accuracy:43.215,     Validation Loss: 0.434, Validation Accuracy:87.114,\n",
      "Epoch 64, Train Loss: 0.741, Train Accuracy:43.211,     Validation Loss: 0.454, Validation Accuracy:86.169,\n",
      "Epoch 65, Train Loss: 0.743, Train Accuracy:43.251,     Validation Loss: 0.477, Validation Accuracy:85.353,\n",
      "Epoch 66, Train Loss: 0.745, Train Accuracy:43.246,     Validation Loss: 0.505, Validation Accuracy:84.676,\n",
      "Epoch 67, Train Loss: 0.747, Train Accuracy:43.227,     Validation Loss: 0.529, Validation Accuracy:84.028,\n",
      "Epoch 68, Train Loss: 0.749, Train Accuracy:43.244,     Validation Loss: 0.565, Validation Accuracy:83.326,\n",
      "Epoch 69, Train Loss: 0.751, Train Accuracy:43.229,     Validation Loss: 0.604, Validation Accuracy:82.667,\n",
      "Epoch 70, Train Loss: 0.753, Train Accuracy:43.255,     Validation Loss: 0.647, Validation Accuracy:82.044,\n",
      "Epoch 71, Train Loss: 0.755, Train Accuracy:43.232,     Validation Loss: 0.680, Validation Accuracy:81.324,\n",
      "Epoch 72, Train Loss: 0.758, Train Accuracy:43.244,     Validation Loss: 0.718, Validation Accuracy:80.612,\n",
      "Epoch 73, Train Loss: 0.760, Train Accuracy:43.246,     Validation Loss: 0.777, Validation Accuracy:79.905,\n",
      "Epoch 74, Train Loss: 0.762, Train Accuracy:43.235,     Validation Loss: 0.831, Validation Accuracy:79.109,\n",
      "Epoch 75, Train Loss: 0.765, Train Accuracy:43.260,     Validation Loss: 0.889, Validation Accuracy:78.456,\n",
      "Epoch 76, Train Loss: 0.767, Train Accuracy:43.239,     Validation Loss: 0.944, Validation Accuracy:77.705,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Train Loss: 0.770, Train Accuracy:43.255,     Validation Loss: 1.005, Validation Accuracy:77.028,\n",
      "Epoch 78, Train Loss: 0.772, Train Accuracy:43.265,     Validation Loss: 1.068, Validation Accuracy:76.385,\n",
      "Epoch 79, Train Loss: 0.775, Train Accuracy:43.260,     Validation Loss: 1.144, Validation Accuracy:75.734,\n",
      "Epoch 80, Train Loss: 0.778, Train Accuracy:43.272,     Validation Loss: 1.215, Validation Accuracy:75.121,\n",
      "Epoch 81, Train Loss: 0.780, Train Accuracy:43.303,     Validation Loss: 1.278, Validation Accuracy:74.639,\n",
      "Epoch 82, Train Loss: 0.783, Train Accuracy:43.302,     Validation Loss: 1.349, Validation Accuracy:74.039,\n",
      "Epoch 83, Train Loss: 0.786, Train Accuracy:43.296,     Validation Loss: 1.426, Validation Accuracy:73.354,\n",
      "Epoch 84, Train Loss: 0.789, Train Accuracy:43.323,     Validation Loss: 1.506, Validation Accuracy:72.814,\n",
      "Epoch 85, Train Loss: 0.792, Train Accuracy:43.323,     Validation Loss: 1.579, Validation Accuracy:72.261,\n",
      "Epoch 86, Train Loss: 0.795, Train Accuracy:43.315,     Validation Loss: 1.652, Validation Accuracy:71.724,\n",
      "Epoch 87, Train Loss: 0.798, Train Accuracy:43.329,     Validation Loss: 1.738, Validation Accuracy:71.271,\n",
      "Epoch 88, Train Loss: 0.801, Train Accuracy:43.303,     Validation Loss: 1.818, Validation Accuracy:70.776,\n",
      "Epoch 89, Train Loss: 0.804, Train Accuracy:43.303,     Validation Loss: 1.893, Validation Accuracy:70.280,\n",
      "Epoch 90, Train Loss: 0.808, Train Accuracy:43.302,     Validation Loss: 1.971, Validation Accuracy:69.766,\n",
      "Epoch 91, Train Loss: 0.811, Train Accuracy:43.303,     Validation Loss: 2.062, Validation Accuracy:69.284,\n",
      "Epoch 92, Train Loss: 0.815, Train Accuracy:43.342,     Validation Loss: 2.147, Validation Accuracy:68.765,\n",
      "Epoch 93, Train Loss: 0.818, Train Accuracy:43.342,     Validation Loss: 2.235, Validation Accuracy:68.326,\n",
      "Epoch 94, Train Loss: 0.822, Train Accuracy:43.357,     Validation Loss: 2.325, Validation Accuracy:67.924,\n",
      "Epoch 95, Train Loss: 0.826, Train Accuracy:43.350,     Validation Loss: 2.417, Validation Accuracy:67.471,\n",
      "Epoch 96, Train Loss: 0.830, Train Accuracy:43.343,     Validation Loss: 2.500, Validation Accuracy:67.049,\n",
      "Epoch 97, Train Loss: 0.834, Train Accuracy:43.356,     Validation Loss: 2.581, Validation Accuracy:66.652,\n",
      "Epoch 98, Train Loss: 0.838, Train Accuracy:43.373,     Validation Loss: 2.654, Validation Accuracy:66.289,\n",
      "Epoch 99, Train Loss: 0.842, Train Accuracy:43.352,     Validation Loss: 2.728, Validation Accuracy:65.872,\n",
      "Epoch 100, Train Loss: 0.846, Train Accuracy:43.338,     Validation Loss: 2.803, Validation Accuracy:65.396,\n",
      "Epoch 101, Train Loss: 0.850, Train Accuracy:43.345,     Validation Loss: 2.888, Validation Accuracy:65.089,\n",
      "Epoch 102, Train Loss: 0.855, Train Accuracy:43.350,     Validation Loss: 2.971, Validation Accuracy:64.803,\n",
      "Epoch 103, Train Loss: 0.859, Train Accuracy:43.355,     Validation Loss: 3.044, Validation Accuracy:64.436,\n",
      "Epoch 104, Train Loss: 0.864, Train Accuracy:43.352,     Validation Loss: 3.123, Validation Accuracy:64.117,\n",
      "Epoch 105, Train Loss: 0.869, Train Accuracy:43.338,     Validation Loss: 3.196, Validation Accuracy:63.806,\n",
      "Epoch 106, Train Loss: 0.873, Train Accuracy:43.341,     Validation Loss: 3.270, Validation Accuracy:63.449,\n",
      "Epoch 107, Train Loss: 0.878, Train Accuracy:43.331,     Validation Loss: 3.351, Validation Accuracy:63.073,\n",
      "Epoch 108, Train Loss: 0.883, Train Accuracy:43.341,     Validation Loss: 3.430, Validation Accuracy:62.646,\n",
      "Epoch 109, Train Loss: 0.888, Train Accuracy:43.359,     Validation Loss: 3.515, Validation Accuracy:62.299,\n",
      "Epoch 110, Train Loss: 0.894, Train Accuracy:43.380,     Validation Loss: 3.588, Validation Accuracy:62.034,\n",
      "Epoch 111, Train Loss: 0.899, Train Accuracy:43.369,     Validation Loss: 3.669, Validation Accuracy:61.755,\n",
      "Epoch 112, Train Loss: 0.904, Train Accuracy:43.381,     Validation Loss: 3.739, Validation Accuracy:61.447,\n",
      "Epoch 113, Train Loss: 0.910, Train Accuracy:43.387,     Validation Loss: 3.801, Validation Accuracy:61.130,\n",
      "Epoch 114, Train Loss: 0.915, Train Accuracy:43.376,     Validation Loss: 3.881, Validation Accuracy:60.756,\n",
      "Epoch 115, Train Loss: 0.921, Train Accuracy:43.374,     Validation Loss: 3.954, Validation Accuracy:60.469,\n",
      "Epoch 116, Train Loss: 0.927, Train Accuracy:43.373,     Validation Loss: 4.015, Validation Accuracy:60.209,\n",
      "Epoch 117, Train Loss: 0.933, Train Accuracy:43.376,     Validation Loss: 4.083, Validation Accuracy:59.973,\n",
      "Epoch 118, Train Loss: 0.939, Train Accuracy:43.361,     Validation Loss: 4.131, Validation Accuracy:59.743,\n",
      "Epoch 119, Train Loss: 0.945, Train Accuracy:43.364,     Validation Loss: 4.194, Validation Accuracy:59.556,\n",
      "Epoch 120, Train Loss: 0.951, Train Accuracy:43.380,     Validation Loss: 4.251, Validation Accuracy:59.270,\n",
      "Epoch 121, Train Loss: 0.958, Train Accuracy:43.369,     Validation Loss: 4.311, Validation Accuracy:58.935,\n",
      "Epoch 122, Train Loss: 0.964, Train Accuracy:43.359,     Validation Loss: 4.369, Validation Accuracy:58.648,\n",
      "Epoch 123, Train Loss: 0.971, Train Accuracy:43.352,     Validation Loss: 4.429, Validation Accuracy:58.370,\n",
      "Epoch 124, Train Loss: 0.977, Train Accuracy:43.369,     Validation Loss: 4.481, Validation Accuracy:58.107,\n",
      "Epoch 125, Train Loss: 0.984, Train Accuracy:43.369,     Validation Loss: 4.535, Validation Accuracy:57.870,\n",
      "Epoch 126, Train Loss: 0.991, Train Accuracy:43.355,     Validation Loss: 4.593, Validation Accuracy:57.585,\n",
      "Epoch 127, Train Loss: 0.998, Train Accuracy:43.340,     Validation Loss: 4.642, Validation Accuracy:57.281,\n",
      "Epoch 128, Train Loss: 1.005, Train Accuracy:43.326,     Validation Loss: 4.693, Validation Accuracy:57.026,\n",
      "Epoch 129, Train Loss: 1.012, Train Accuracy:43.331,     Validation Loss: 4.751, Validation Accuracy:56.872,\n",
      "Epoch 130, Train Loss: 1.020, Train Accuracy:43.338,     Validation Loss: 4.801, Validation Accuracy:56.666,\n",
      "Epoch 131, Train Loss: 1.027, Train Accuracy:43.353,     Validation Loss: 4.855, Validation Accuracy:56.463,\n",
      "Epoch 132, Train Loss: 1.035, Train Accuracy:43.347,     Validation Loss: 4.916, Validation Accuracy:56.219,\n",
      "Epoch 133, Train Loss: 1.043, Train Accuracy:43.347,     Validation Loss: 4.966, Validation Accuracy:56.045,\n",
      "Epoch 134, Train Loss: 1.050, Train Accuracy:43.331,     Validation Loss: 5.029, Validation Accuracy:55.857,\n",
      "Epoch 135, Train Loss: 1.058, Train Accuracy:43.326,     Validation Loss: 5.072, Validation Accuracy:55.739,\n",
      "Epoch 136, Train Loss: 1.066, Train Accuracy:43.331,     Validation Loss: 5.123, Validation Accuracy:55.579,\n",
      "Epoch 137, Train Loss: 1.075, Train Accuracy:43.333,     Validation Loss: 5.173, Validation Accuracy:55.470,\n",
      "Epoch 138, Train Loss: 1.083, Train Accuracy:43.340,     Validation Loss: 5.220, Validation Accuracy:55.254,\n",
      "Epoch 139, Train Loss: 1.091, Train Accuracy:43.343,     Validation Loss: 5.274, Validation Accuracy:55.128,\n",
      "Epoch 140, Train Loss: 1.100, Train Accuracy:43.338,     Validation Loss: 5.313, Validation Accuracy:55.038,\n",
      "Epoch 141, Train Loss: 1.109, Train Accuracy:43.341,     Validation Loss: 5.365, Validation Accuracy:54.898,\n",
      "Epoch 142, Train Loss: 1.117, Train Accuracy:43.343,     Validation Loss: 5.407, Validation Accuracy:54.696,\n",
      "Epoch 143, Train Loss: 1.126, Train Accuracy:43.333,     Validation Loss: 5.452, Validation Accuracy:54.473,\n",
      "Epoch 144, Train Loss: 1.135, Train Accuracy:43.347,     Validation Loss: 5.493, Validation Accuracy:54.353,\n",
      "Epoch 145, Train Loss: 1.145, Train Accuracy:43.340,     Validation Loss: 5.545, Validation Accuracy:54.222,\n",
      "Epoch 146, Train Loss: 1.154, Train Accuracy:43.326,     Validation Loss: 5.592, Validation Accuracy:54.033,\n",
      "Epoch 147, Train Loss: 1.163, Train Accuracy:43.329,     Validation Loss: 5.636, Validation Accuracy:53.878,\n",
      "Epoch 148, Train Loss: 1.173, Train Accuracy:43.319,     Validation Loss: 5.678, Validation Accuracy:53.765,\n",
      "Epoch 149, Train Loss: 1.182, Train Accuracy:43.317,     Validation Loss: 5.714, Validation Accuracy:53.633,\n",
      "Epoch 150, Train Loss: 1.192, Train Accuracy:43.322,     Validation Loss: 5.756, Validation Accuracy:53.493,\n",
      "Epoch 151, Train Loss: 1.202, Train Accuracy:43.336,     Validation Loss: 5.801, Validation Accuracy:53.376,\n",
      "Epoch 152, Train Loss: 1.212, Train Accuracy:43.326,     Validation Loss: 5.846, Validation Accuracy:53.237,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153, Train Loss: 1.222, Train Accuracy:43.315,     Validation Loss: 5.883, Validation Accuracy:53.097,\n",
      "Epoch 154, Train Loss: 1.233, Train Accuracy:43.301,     Validation Loss: 5.918, Validation Accuracy:52.972,\n",
      "Epoch 155, Train Loss: 1.243, Train Accuracy:43.311,     Validation Loss: 5.949, Validation Accuracy:52.910,\n",
      "Epoch 156, Train Loss: 1.254, Train Accuracy:43.310,     Validation Loss: 5.982, Validation Accuracy:52.772,\n",
      "Epoch 157, Train Loss: 1.264, Train Accuracy:43.304,     Validation Loss: 6.012, Validation Accuracy:52.610,\n",
      "Epoch 158, Train Loss: 1.275, Train Accuracy:43.317,     Validation Loss: 6.048, Validation Accuracy:52.408,\n",
      "Epoch 159, Train Loss: 1.286, Train Accuracy:43.317,     Validation Loss: 6.077, Validation Accuracy:52.296,\n",
      "Epoch 160, Train Loss: 1.297, Train Accuracy:43.320,     Validation Loss: 6.106, Validation Accuracy:52.186,\n",
      "Epoch 161, Train Loss: 1.308, Train Accuracy:43.334,     Validation Loss: 6.136, Validation Accuracy:52.059,\n",
      "Epoch 162, Train Loss: 1.320, Train Accuracy:43.329,     Validation Loss: 6.166, Validation Accuracy:51.921,\n",
      "Epoch 163, Train Loss: 1.331, Train Accuracy:43.336,     Validation Loss: 6.193, Validation Accuracy:51.865,\n",
      "Epoch 164, Train Loss: 1.343, Train Accuracy:43.341,     Validation Loss: 6.230, Validation Accuracy:51.726,\n",
      "Epoch 165, Train Loss: 1.354, Train Accuracy:43.341,     Validation Loss: 6.260, Validation Accuracy:51.613,\n",
      "Epoch 166, Train Loss: 1.366, Train Accuracy:43.348,     Validation Loss: 6.289, Validation Accuracy:51.494,\n",
      "Epoch 167, Train Loss: 1.378, Train Accuracy:43.346,     Validation Loss: 6.321, Validation Accuracy:51.403,\n",
      "Epoch 168, Train Loss: 1.390, Train Accuracy:43.364,     Validation Loss: 6.351, Validation Accuracy:51.314,\n",
      "Epoch 169, Train Loss: 1.403, Train Accuracy:43.374,     Validation Loss: 6.378, Validation Accuracy:51.201,\n",
      "Epoch 170, Train Loss: 1.415, Train Accuracy:43.362,     Validation Loss: 6.410, Validation Accuracy:51.069,\n",
      "Epoch 171, Train Loss: 1.428, Train Accuracy:43.358,     Validation Loss: 6.441, Validation Accuracy:50.950,\n",
      "Epoch 172, Train Loss: 1.440, Train Accuracy:43.360,     Validation Loss: 6.475, Validation Accuracy:50.908,\n",
      "Epoch 173, Train Loss: 1.453, Train Accuracy:43.350,     Validation Loss: 6.503, Validation Accuracy:50.845,\n",
      "Epoch 174, Train Loss: 1.466, Train Accuracy:43.366,     Validation Loss: 6.534, Validation Accuracy:50.727,\n",
      "Epoch 175, Train Loss: 1.479, Train Accuracy:43.372,     Validation Loss: 6.556, Validation Accuracy:50.643,\n",
      "Epoch 176, Train Loss: 1.492, Train Accuracy:43.367,     Validation Loss: 6.581, Validation Accuracy:50.580,\n",
      "Epoch 177, Train Loss: 1.506, Train Accuracy:43.372,     Validation Loss: 6.610, Validation Accuracy:50.490,\n",
      "Epoch 178, Train Loss: 1.519, Train Accuracy:43.360,     Validation Loss: 6.627, Validation Accuracy:50.420,\n",
      "Epoch 179, Train Loss: 1.533, Train Accuracy:43.357,     Validation Loss: 6.646, Validation Accuracy:50.338,\n",
      "Epoch 180, Train Loss: 1.546, Train Accuracy:43.352,     Validation Loss: 6.668, Validation Accuracy:50.275,\n",
      "Epoch 181, Train Loss: 1.560, Train Accuracy:43.353,     Validation Loss: 6.695, Validation Accuracy:50.219,\n",
      "Epoch 182, Train Loss: 1.574, Train Accuracy:43.364,     Validation Loss: 6.719, Validation Accuracy:50.149,\n",
      "Epoch 183, Train Loss: 1.588, Train Accuracy:43.353,     Validation Loss: 6.743, Validation Accuracy:50.107,\n",
      "Epoch 184, Train Loss: 1.603, Train Accuracy:43.359,     Validation Loss: 6.759, Validation Accuracy:50.032,\n",
      "Epoch 185, Train Loss: 1.617, Train Accuracy:43.351,     Validation Loss: 6.785, Validation Accuracy:49.948,\n",
      "Epoch 186, Train Loss: 1.632, Train Accuracy:43.357,     Validation Loss: 6.806, Validation Accuracy:49.906,\n",
      "Epoch 187, Train Loss: 1.646, Train Accuracy:43.345,     Validation Loss: 6.828, Validation Accuracy:49.830,\n",
      "Epoch 188, Train Loss: 1.661, Train Accuracy:43.329,     Validation Loss: 6.848, Validation Accuracy:49.713,\n",
      "Epoch 189, Train Loss: 1.676, Train Accuracy:43.325,     Validation Loss: 6.867, Validation Accuracy:49.580,\n",
      "Epoch 190, Train Loss: 1.691, Train Accuracy:43.320,     Validation Loss: 6.888, Validation Accuracy:49.524,\n",
      "Epoch 191, Train Loss: 1.706, Train Accuracy:43.324,     Validation Loss: 6.908, Validation Accuracy:49.461,\n",
      "Epoch 192, Train Loss: 1.722, Train Accuracy:43.308,     Validation Loss: 6.932, Validation Accuracy:49.379,\n",
      "Epoch 193, Train Loss: 1.737, Train Accuracy:43.308,     Validation Loss: 6.957, Validation Accuracy:49.344,\n",
      "Epoch 194, Train Loss: 1.753, Train Accuracy:43.311,     Validation Loss: 6.979, Validation Accuracy:49.254,\n",
      "Epoch 195, Train Loss: 1.769, Train Accuracy:43.324,     Validation Loss: 6.999, Validation Accuracy:49.170,\n",
      "Epoch 196, Train Loss: 1.785, Train Accuracy:43.320,     Validation Loss: 7.016, Validation Accuracy:49.106,\n",
      "Epoch 197, Train Loss: 1.801, Train Accuracy:43.320,     Validation Loss: 7.034, Validation Accuracy:49.050,\n",
      "Epoch 198, Train Loss: 1.817, Train Accuracy:43.320,     Validation Loss: 7.051, Validation Accuracy:48.994,\n",
      "Epoch 199, Train Loss: 1.833, Train Accuracy:43.310,     Validation Loss: 7.072, Validation Accuracy:48.944,\n",
      "Epoch 200, Train Loss: 1.850, Train Accuracy:43.308,     Validation Loss: 7.088, Validation Accuracy:48.873,\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "training_losses_occ, training_accuracies_occ = [], []\n",
    "validations_losses_occ, validations_accuracies_occ = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_tr, y_tr in train_ds:\n",
    "        x_pos = tf.convert_to_tensor(X_tr.numpy()[np.where(y_tr.numpy()==0)])\n",
    "        x_neg = tf.convert_to_tensor(X_tr.numpy()[np.where(y_tr.numpy()==1)])\n",
    "        results = train_step(X_tr=X_tr, y_tr=y_tr, x_pos=x_pos, x_neg=x_neg)\n",
    "        \n",
    "        training_losses_occ.append(train_loss.result().numpy())\n",
    "        training_accuracies_occ.append(train_accuracy.result().numpy())\n",
    "        \n",
    "    for X_val, y_val in val_ds:\n",
    "        test_step(X_val, y_val)\n",
    "        \n",
    "        validations_losses_occ.append(test_loss.result().numpy())\n",
    "        validations_accuracies_occ.append(test_accuracy.result().numpy())\n",
    "    \n",
    "    template = 'Epoch {}, Train Loss: {:.3f}, Train Accuracy:{:.3f}, \\\n",
    "    Validation Loss: {:.3f}, Validation Accuracy:{:.3f},'\n",
    "    \n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result().numpy(),\n",
    "                         train_accuracy.result().numpy()*100,\n",
    "                           \n",
    "                         test_loss.result().numpy(),\n",
    "                         test_accuracy.result().numpy()*100),)\n",
    "    \n",
    "     # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "model_occ.save_weights(\"NN-ckecks/OCC_Eope\"+ name_of_particle +\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"occ_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               multiple                  53760     \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               multiple                  8224      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          multiple                  33        \n",
      "=================================================================\n",
      "Total params: 62,017\n",
      "Trainable params: 62,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_occ.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.99,  nan]),\n",
       " array([1., 0.]),\n",
       " array([0.99,  nan]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_occ = OccModel()\n",
    "new_model_occ.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6))\n",
    "\n",
    "# Since In this implementation instead of weight we are dealing \n",
    "# with codes and classes therefore the traditional serialization and\n",
    "# deserialization is not possible. So we have to first initialze\n",
    "# the model (which is code) and then load the weights \n",
    "# Ref: https://colab.research.google.com/drive/172D4jishSgE3N7AO6U2OKAA_0wNnrMOq#scrollTo=OOSGiSkHTERy\n",
    "\n",
    "cntr = 0\n",
    "for i, j in train_ds:\n",
    "    if cntr == 0:\n",
    "        new_model_occ.train_on_batch(i[:1], j[:1])\n",
    "    cntr += 1 \n",
    "\n",
    "# new_model_occ.load_weights('NN-ckecks/ThreeLayerNN_model'+ name_of_particle+'.h5')\n",
    "test_predictions = new_model_occ.predict(X_test)\n",
    "probabilities = tf.nn.sigmoid(test_predictions)\n",
    "labels_pred_occ = tf.argmax(probabilities, axis=1)\n",
    "\n",
    "\n",
    "labels_true_occ = []\n",
    "for i, j in test_ds:\n",
    "    for k in j.numpy():\n",
    "        labels_true_occ.append(k)\n",
    "\n",
    "PPV3, TPR3, FSCORE3, FNR3, FPR3, TNR3 = perf_measure(y_true=labels_true_occ, y_pred=labels_pred_occ)\n",
    "\n",
    "\n",
    "PPV3, TPR3, FSCORE3, FNR3, TNR3, # FPR3, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "tfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
